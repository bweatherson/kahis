It is not trivial to prove that my version of IRT satisfies these closure conditions. One reason for this is that I have not stated a sufficient condition for knowledge. all that I have said is that knowledge is incompatible with a certain kind of caution. So in principle I cannot show that if some conditions obtain then someone knows something. What I can show, is that introducing new conditions linking knowledge with relevant questions as I have done does not introduce new violations of the closure conditions. 

But it turns out that even showing this is not completely trivial. Imagine yet another version of the red blue game.^[This game will resemble the examples that @Zweber2016 and @AndersonHawthorne2019b use to raise doubts about whether pragmatic theories like mine reall do endorse single premise closure.] In this game, both of the sentences are claims about history that are well supported without being certain. And both of them are supported in the very same way. It turns out to be a little distracting to use concrete examples in this case, so just call the claims A and B. And imagine that the player read both of these claims in the same reliable but not infallible history book, and she knows the book is reliable but not infallible, and she aims to maximise her expected returns. Then all four of the following things are true about the game.

1. Unconditionally, the player is indifferent between playing red-true and playing blue-true.
2. Conditional on $A$, the player prefers red-true to blue-true, because red-true will certainly return $50 while blue-true is not completely certain to win the money.
3. Conditional on $B$, the player prefers blue-true to red-true, because blue-true will certainly return $50 while red-true is not completely certain to win the money.
4. Conditional on $A \wedge B$, the player is back to being indifferent between playing red-true and playing blue-true.

From 1, 2 and 3, it follows in my version of IRT that the player does not know either $A$ or $B$. After all, conditionalising on either one of them changes her answer to a relevant question. The question being, _Which option maximises my expected returns?_, where this is understood as a mention-all question. 

But look what happens at point 4. Conditionalising on $A \wedge B$ does not change the answer to that question. So, assuming there is no other reason that the player does not know $A \wedge B$, arguably she does know $A \wedge B$. And that would be absurd; how could she know a conjunction without knowing either conjunct?

Here is how I used to answer this question. Define a technical notion of interest. Say that a person is interested in a conditional question _If p, Q?_ if they are interested, in the ordinary sense, in both the true-false question _p?_ and they are interested in the question _Q?_. And if conditionalising on a proposition changes (or should change) their answer to any question they are interested in in this technical sense, then they don't know that proposition. This solves the problem because conditionalising on $A \wedge B$ does change their answer to the question _If A, which option maximises expected returns?_ on its mention-some reading. So even though 4 is correct, this does pose a problem for closure.

But this is not an entirely satisfactory solution for two reasons. One is that it seems extremely artificial to say that someone is interested in these conditional questions that they have never even formulated. Another is that it is hard to motivate why we should care that conditionalisation changes (or should change) one's answers to these artificial questions.

There was something right about the answer I used to give. It is that we should not just look at whether conditionalisation changes the answers a person gives to questions they are interested in. We should also look at whether it changes things 'under the hood'; whether it changes how they get to that answer. The idea of my old theory was that looking at these artificial questions was a way to indirectly look under the hood. But it is not clear why we should look for these indirect approaches, rather than just looking at what is going on in the player's mind.^[Well, unless one is a behaviorist, and so thinks the answers to related questions are all there is to what is going on under the hood. But we should not import that much behaviorism into our epistemology.]

So let's look again at the two questions that are relevant. And this time, don't think about what answer the player gives, but about how they get to that answer.

5. Which option maximises expected returns?
6. If $A \wedge B$, which option maximises expected returns?

On the most natural way to understand what the player does, there will be a step in her answer to 5 that has no parallel in her answer to 6. 

She will note, and rely on, the fact that she has equally good evidence for $A$ as for $B$. That is why each option is equally good by her lights. The equality of evidence really matters. If she had read that $A$ in three books, but only one of those books added that $B$, then the two options would not have the same expected returns. She should check that nothing like this is going on; that the evidence really is equally balanced. 

But nothing like this happens in answering 6. In that case, $A \wedge B$ is stipulated to be given. So there is no question about how good the evidence for either is. When answering a question about what to do if a condition obtains, we don't ask how good the evidence for the condition is. We just assume that it holds. So in answering 6, there is no step that acknowledges the equality of the evidence for both $A$ and $B$.

So in fact the player does not answer the two questions the same way. She ends up with the same conclusion, but she gets there by a different means. And that is enough, I say, to make it a different answer. If she knew $A \wedge B$, she could follow exactly the same steps in answering 5 and 6, but she cannot.

What should we say if she does follow the same steps? If this is irrational, nothing changes, since what matters for knowledge is which questions should be answered the same way, not which questions are answered the same way. (It does matter for belief, but that is not the current topic.) So I will assume that it is possible for the player to rationally answer both questions the same way. (I will have much more to say about why this is a coherent assumption in chapter \@ref(ties).)

The way she should answer 6 is to take $A \wedge B$ as given. And hence she will take either option, red-true or blue-true, as being equivalent to just taking $50. And she knows that is the best she can do in the game. So in answering question 6, she will take it as given that both of these options are maximally good.

By hypothesis, she is answering question 5 and question 6 the same way. So she will take it to be part of the setup of question 5 that both options return a sure $50 After all, that is part of the setup of question 6. But if she takes that as given, then conditionalising on either $A$ or $B$ does not change her expected returns. So now claims 2 and 3 are wrong; conditionalising on either conjunct won't make a difference because she treats each conjunct as given.

And that is the totally general case. Assume that someone has competently deduced $Y$ from $X$, and they know $X$. So they are entitled to answer the questions _Q?_ and _If X, Q?_ by the same method. Since the method for the latter takes _X_ as given, so can the method for the former. So they can answer _Q?_ taking _X_ as given. What one can appropriately take as given is closed under competent deduction? (Why? Because in the answer to _Q?_ that starts with _X_, you can just go on to derive _Y_, and then see that it is also a way to answer _If Y, Q?_.) So they can answer _Q?_ taking _Y_ as given. So they can answer _Q?_ in the same way they answer _If Y, Q?_.

So assuming there is no other reason to deny **Single Premise Closure**, adding a clause about how one may answer questions does not give us a new reason to deny it.

