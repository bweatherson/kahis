# The Preface Paradox {#preface}



## Solving the Paradox

In section \@ref(lockean), I argued against the Lockean thesis that full belief just is degree of belief above a threshold. And in particular I stressed in subsection \@ref(closure) that the Lockean had a problem with closure. They were committed to the view that one could, with perfect rationality and perfect awareness, believe that $p$, believe that $q$, and decline to believe that $p \wedge q$. This seems absurd. It means that if they are answering sincerely, we can have the following conversation.

> Me: Is $p$ true?
> Lockean: Yes.
> Me: Is $q$ true?
> Lockean: Yes.
> Me: So $p$ and $q$ are both true?
> Lockean: Yes.
> Me: So $p \wedge q$ is true?
> Lockean: Well, not so fast, we can't be sure about that.

And that doesn't seem like a particularly good place to have ended up. But there is one prominent reason to end up there. David @Christensen2005 argues that reflection on the preface paradox shows that we need to have some kind of restriction on and-introduction. And the best restriction, he argues, will end up being one that makes the Lockean position look plausible. 

Note that I'm here using 'and-introduction' as the name of a principle on rational inference. No one is denying that it is a good rule of implication. More precisely, I'm using it as the name of the following principle.

And-introduction
:    If someone rationally believes $p$, and rationally believes $q$, and the question of whether $p \wedge q$ is true is a live one, then they are rationally entitled to believe $p \wedge q$, and if they decline to believe $p \wedge q$, they are not entitled to keep believing both $p$ and $q$.

Here is Christensen's version of the preface paradox, which is meant to motivate a restriction on principles like and-introduction that link inference too tightly to logical implication.

> We are to suppose that an apparently rational person has written a long non-fiction book---say, on history. The body of the book, as is typical, contains a large number of assertions. The author is highly confident in each of these assertions; moreover, she has no hesitation in making them unqualifiedly, and would describe herself (and be described by others) as believing each of the book's many claims. But she knows enough about the difficulties of historical scholarship to realize that it is almost inevitable that at least a few of the claims she makes in the book are mistaken. She modestly acknowledges this in her preface, by saying that she believes the book will be found to contain some errors, and she graciously invites those who discover the errors to set her straight. [@Christensen2005 33-4]

Christensen thinks such an author might be rational in every one of her beliefs, even though these are all inconsistent. And he notes this is a quite ordinary belief. It's not like we have to go to fake barn country to find a
counterexample to and-introduction. But it seems to me that we need two quite strong idealisations in order to get a real counterexample here.

The first of these is discussed by Ishani @Maitra2010, and is briefly mentioned by Christensen in setting out the problem. We only have a counterexample to and-introduction if the author believes every thing she writes in her book. Indeed, we only have a counterexample if she rationally believes every one of them. But we'll assume a rational author who only believes what she is rational to believe.

This seems unlikely. An author of a historical book is like a detective who, when asked to put forward her best guess about what explains the evidence, says "If I had to guess, I'd say ..." and then launches into spelling out her hypothesis. It seems clear that she need not *believe* the truth of her hypothesis. If she did that, she could not later learn it was true, because you can't learn the truth of something you already believe. And she wouldn't put any effort into investigating alternative suspects. But she can come to learn her hypothesis was true, and it would be rational to investigate other suspects. As Maitra suggests, we should understand scholarly assertions as being governed by the same kind of rules that govern detectives making the kind of speech being contemplated here. And those rules don't require that the speaker believe the things they say without qualification. The picture is that the little prelude the detective explicitly says is implicit in all scholarly work.

Christensen makes two objections to the suggestions that the author doesn't believe what she says. First, he notes that the author doesn't qualify their assertions. But neither does our detective qualify most individual sentences. Second, he notes that most people would describe our author as believing her assertions. But it is also natural to describe our detective as believing the things she says in her speech. It's natural to say things like "She thinks it was the butler, with the lead pipe, in the hallm" in reporting her hypothesis. 

Alternatively, we might try to use an argument by Timothy @Williamson2000 to argue that speakers must believe what they say. He notes that if if speakers don't believe whatthey say, we won't have an explanation of why Moore paradoxical sentences like "The butler did it, but I don't believe the butler did it," are always defective. But note that our detective, who is explicitly asked for a guess, still sounds like she's making a mistake if she says "The butler did it, but I don't believe the butler did it." The detective can't even say that in setting out what is explicitly a hypothesis. So whatever explains why we can't say this in ordinary speech, it can't be that we are required to say what we believe.

It is plausible that for some kinds of books, the author should only say things they believe. This is probably true for travel guides, for example. Interestingly, casual observation suggests that authors of such books are much less likely to write modest prefaces. This makes some sense if those books can only include statements their authors believe, and the authors believe the conjunctions of what they believe.

The second idealisation is stressed by Simon @Evnine1999. The following situation does not involve Pedro believing anything inconsistent.

- Pedro believes that what Manny just said, whatever it was, is false.
- Manny just said that the stands at Fenway Park are green.
- Pedro believes that the stands at Fenway Park are green.

If we read the first claim de dicto, that Pedro believes that Manny just said something false, then there is no inconsistency. (Unless Pedro also believes that what Manny just said was that the stands in Fenway Park are green.) But if we read it de re, that the thing Manny just said is one of the things Pedro believes to be false, then the situation does involve Pedro being inconsistent. 

The same is true when the author believes that one of the things she says in her book is mistaken. If we understand what she says de dicto, there is no contradiction in her beliefs. It has to be understood de re before we get a logical problem. And the fact is that most authors do not have de re attitudes towards the claims made in their book. Most authors don't even remember everything that's in their books. (I'm not sure I remember how this chapter started, let alone this book.) Some may argue that authors don't even have the capacity to consider a proposition as long and complicated as the conjunction of all the claims in their book. Christensen considers this objection, but says it isn't a serious problem.

> It is undoubtedly true that ordinary humans cannot entertain book-length conjunctions. But surely, agents who do not share this fairly *superficial* limitation are easily conceived. And it seems just as wrong to say of such agents that they are rationally required to believe in the inerrancy of the books they write. (38: my emphasis)

We should be suspicious of the intuition that Christensen is relying on here. He argues idealising away from author's forgetfulness about what they've written shouldn't change our intuitions about the case. But the preface paradox gets a lot of its (apparent) force from intuitions about what attitude we should have towards real books. Once we make it clear that the real life cases are not relevant to the paradox, the intuitions become rather murky. And the idea that there are failures of and-introduction that arise in everyday cases, that aren't like weird fake barn cases, has falled away a little at this point.

Ultimately, I think the first idealisation is more important. We believers in and-introduction don't think that authors should believe their books are inerrant. Rather, following a position that stretches back at least to @Stalnaker1984, they shouldn't fully believe each individual statement if they don't believe the conjunction. They don't have to have any particular quantified attitude to each claim in the book. They can simply think that each claim is probably true, and decline to associate this attitude with any numerical credence.

Proponents of the preface paradox know that this is a possible response. The standard response is that it is impractical. Here is Christensen on this point.

> It is clear that our everyday binary way of talking about beliefs has immense practical advantages over a system which insisted on some more fine-grained reporting of degrees of confidence ... At a minimum, talking about people as believing, disbelieving, or withholding belief has at least as much point as do many of the imprecise ways we have of talking about things that can be described more precisely. (96)

Richard Foley makes a similar point.

> There are deep reasons for wanting an epistemology of beliefs, reasons that epistemologies of degrees of belief by their very nature cannot possibly accommodate. [@Foley1993 170, my emphasis]

It's easy to make too much of this point. It's a lot easier to triage propositions into TRUE, FALSE and NOT SURE and work with those categories than it is to work assign precise numerical probabilities to each proposition. But these are not the only options. Foley's discussion subsequent to the above quote sometimes suggests they are, especially when he contrasts the triage with "indicat\[ing\] as accurately as I can my degree of confidence in each assertion that I defend." (171) 

But really it isn't much harder to add two more categories, PROBABLY TRUE and PROBABLY FALSE to those three, and work with that five-way division rather than a three-way division. It's not clear that humans as they are actually constructed have a strong preference for the three-way over the five-way division, and even if they do, I'm not sure in what sense this is a 'deep' fact about them.

Once we have the five-way division, it is clear what authors should do if they want to respect and-introduction. For any conjunction that they don't believe (i.e. classify as true), they should not believe one of the conjuncts. But of course they can classify every conjunct as probably true, even if they think the conjunction is false, or even certainly false. Still, might it not be considered something of an idealisation to say rational authors must make this five-way distinction amongst
propositions they consider? Yes, but it's no more of an idealisation than we need to set up the preface paradox in the first place. To use the preface paradox to find an example of someone who reasonably violates closure, we need to insist on the following three constraints.

1. They are part of a research community where only asserting propositions you believe is compatible with active scholarship;
2.  They know exactly what is in their book, so they are able to believe that one of the propositions in the book is mistaken, where this is understood de re; but
3. They are unable to effectively function if they have to effect a five-way, rather than a three-way, division amongst the propositions they consider.

Put more graphically, to motivate the preface paradox we have to think that our inability to have de re thoughts about the contents of books is a "superficial constraint", but our preference for working with a three-way rather than a five-way division is a "deep" fact about our cognitive system. Maybe each of these attitudes could be plausible taken on its own (though I'm sceptical of that) but the conjunction is very hard to motivate.

Even if someone who satisfied precisely these idealisations was possible, something that isn't at all obvious to me, it isn't clear why the norms applicable to them have any relevance to us. That is, it might be that for someone who satisfied 1, 2 and 3, then violating and-introduction would be a way to make the best of a bad situation. But it wouldn't follow that violating and-introduction is rationally permissible. It might be that this is the least bad way to deal with the constraints that have been imposed.

## Too Little Closure? {#toolittleclosure}

At this point, one might worry that I've argued for a conclusion that is stronger than what I wanted to defend. While my version of IRT endorses and-introduction as stated, it does not endorse a version with some of the restrictions removed. In particular, it doesn't endorse a version of the view that says whenever a rational person believes $p$ and believes $q$, they also believe $p \wedge q$. And I rather doubt one could endorse that, while holding on to anything like the picture I'm presenting here.

So I'll end by defending these restrictions. Let's start by looking at a very important argument for (something like) and-introduction, taken from Stalnaker's _Inquiry_.

> Reasoning in this way from accepted premises to their deductive consequences ($P$, also $Q$, therefore $R$) does seem perfectly straightforward. Someone may object to one of the premises, or to the validity of the argument, but one could not intelligibly agree that the premises are each acceptable and the argument valid, while objecting to the acceptability of the conclusion. [@Stalnaker1984 92]

Stalnaker's wording here is typically careful. The relevant question isn't whether we can accept $p$, accept $q$, accept $p$ and $q$ entail $r$, and reject $r$. As Christensen [-@Christensen2005 Ch. 4] notes, this is impossible even on the Lockean view, as long as the threshold for belief is above 2/3. The real question is whether we can accept $p$, accept $q$, accept $p$ and $q$ entail $r$, and fail to accept $r$. And this is always a live possibility on any version of the Lockean view.

But it's important to note how active the verbs in Stalnaker's description are. When faced with a valid argument we have to *object* to one of the premises, or the validity of the argument. What we can't do is *agree* to the premises and the validity of the argument, while *objecting* to the conclusion. I agree. If we are really agreeing to some propositions, and objecting to others, then all those
propositions are live in the sense relevant to and-introduction. And in that case believing the conjunction of whatever is believed is mandatory. This doesn't tell us what we have to do if we haven't previously made the propositions salient in the first place.

Where I've ended up is very similar to a position that Gilbert Harman endorses in  *Change in View*. There Harman endorses the following principle. (At least he endorses it as true -- he doesn't seem to think it is particularly explanatory because it is a special case of a more general interesting principle.)

> One has reason to believe $P$ if one *recognizes* that $P$ is logically
implied by one's view. [@Harman1986 17]

This is, like the passage from Stalnaker I just quoted, both correct and careful. Notably, it does not say that this reason is a conclusive reason. After all, one might change one's view rather than accept the implication. But one does have reason to believe $p$ in such a situation.

My main objection to those who use the preface paradox to argue against and-introduction is that they give us a mistaken picture of what we have to do epistemically. When one has inconsistent beliefs, or one doesn't believe some consequence of one's beliefs, that is something one has a reason to deal with at some stage. It is something that is to do for one; i.e., it should be on one's 'to-do' list.

When we say that we have things to do, we don't mean that we have to do them *right now*, or instead of everything else. My current list of things to do includes cleaning my office. Yet I'm working on this book and, given the relative importance of a completed book and a clean office, rightly so. 

We can have the job of cleaning up our epistemic house as something to do while recognising that we can quite rightly do other things first. But it's a serious mistake to infer from the permissibility of doing other things that cleaning up our epistemic house (or our office) isn't something to be done. The office won't clean itself after all, and eventually this becomes a problem.

There is a possible complication when it comes to tasks that are very low priority. Imagine someone with an attic that is both somewhat messy, and also rarely used because it is so impractical. It is, in a sense, to be cleaned. At least, it could be cleaner. But there are no imaginable circumstances under which something else wouldn't be higher priority. Given that, should we really leave *clean the attic* on the list of things to be done? Similarly, there might be implications of one's beliefs that one hasn't deduced that it couldn't possibly be worth my time to figure out. Are they things to be done? I think it's worthwhile recording them as such, because otherwise we might miss opportunities to deal with them in the process of doing something else. I don't need to put off anything else in order to clean the attic, but if I'm up there for independent reasons I should bring down some of the junk. Similarly, I don't need to follow through implications mostly irrelevant to my interests, but if those propositions come up for independent reasons, I should deal with the fact that some things I believe imply something I don't believe. Having it be the case that all implications from things we believe to things we don't believe constitute jobs to do (possibly in the loose sense that cleaning my attic is something to do) has the right implications for what epistemic duties we do and don't have.

While waxing metaphorical, it seems time to pull out a rather helpful Rylean metaphor. It's from the discussion in @Ryle1949 of what we'd now call the inference/implication distinction. (This is a large theme of chapter 9, see particularly pages 292-309.) Ryle's point in these passages, as it frequently is throughout the book, is to stress that minds are fundamentally active, and the activity of a mind cannot be easily recovered from its end state. Although Ryle doesn't use this language, his point is that we shouldn't confuse the difficult activity of drawing inferences with the smoothness and precision of a logical implication. The language Ryle does use is more picturesque. He compares the easy work a farmer does when sauntering down a path from the hard work he did when building the path. A good argument, in philosophy or mathematics or elsewhere, is like a well made path that permits sauntering from the start to finish without
undue strain. But from that it doesn't follow that the task of coming up with that argument, of building that path in Ryle's metaphor, was easy work. The easiest paths to walk are often the hardest to build. Path-building, smoothing out our beliefs so they are consistent and closed under implication, is hard work, even when the finished results look clean and straightforward. Its work that we shouldn't do unless we need to. But making sure our beliefs are closed under entailment even with respect to irrelevant propositions is suspiciously like the
activity of buildings paths between points without first checking you need to walk between them.

So it's fine to believe $p$, believe $q$, and fail to believe $p \wedge q$, as long as it isn't the case that all three of those propositions are relevant to one's intersts at any one time. There is a tension there, and it is a tension that is to be relieved eventually. But the time to relieve it might never arise, and when it does, there are a lot of ways to deal with the situation.
