<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Inquiry | Knowledge</title>
  <meta name="description" content="A defence of an interest-relative theory of knowledge" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Inquiry | Knowledge" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/tree.jpg" />
  <meta property="og:description" content="A defence of an interest-relative theory of knowledge" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Inquiry | Knowledge" />
  
  <meta name="twitter:description" content="A defence of an interest-relative theory of knowledge" />
  <meta name="twitter:image" content="/tree.jpg" />

<meta name="author" content="Brian Weatherson" />


<meta name="date" content="2022-10-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="knowledge.html"/>
<link rel="next" href="ties.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="index.html">Knowledge: A Human Interest Story</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#website-instructions"><i class="fa fa-check"></i>Website Instructions</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>1</b> Background</a></li>
<li class="chapter" data-level="2" data-path="interests.html"><a href="interests.html"><i class="fa fa-check"></i><b>2</b> Interests</a>
<ul>
<li class="chapter" data-level="2.1" data-path="interests.html"><a href="interests.html#redblue"><i class="fa fa-check"></i><b>2.1</b> Red or Blue?</a></li>
<li class="chapter" data-level="2.2" data-path="interests.html"><a href="interests.html#fourfamilies"><i class="fa fa-check"></i><b>2.2</b> Four Families</a></li>
<li class="chapter" data-level="2.3" data-path="interests.html"><a href="interests.html#orthodox"><i class="fa fa-check"></i><b>2.3</b> Against Orthodoxy</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="interests.html"><a href="interests.html#orthodoxmoore"><i class="fa fa-check"></i><b>2.3.1</b> Moore’s Paradox</a></li>
<li class="chapter" data-level="2.3.2" data-path="interests.html"><a href="interests.html#superknow"><i class="fa fa-check"></i><b>2.3.2</b> Super Knowledge to the Rescue?</a></li>
<li class="chapter" data-level="2.3.3" data-path="interests.html"><a href="interests.html#probrescue"><i class="fa fa-check"></i><b>2.3.3</b> Rational Credences to the Rescue?</a></li>
<li class="chapter" data-level="2.3.4" data-path="interests.html"><a href="interests.html#orthodoxevidence"><i class="fa fa-check"></i><b>2.3.4</b> Evidential Probability</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="interests.html"><a href="interests.html#oddsandstakes"><i class="fa fa-check"></i><b>2.4</b> Odds and Stakes</a></li>
<li class="chapter" data-level="2.5" data-path="interests.html"><a href="interests.html#whatinterests"><i class="fa fa-check"></i><b>2.5</b> Theoretical Interests Matter</a></li>
<li class="chapter" data-level="2.6" data-path="interests.html"><a href="interests.html#global"><i class="fa fa-check"></i><b>2.6</b> Global Interest Relativity</a></li>
<li class="chapter" data-level="2.7" data-path="interests.html"><a href="interests.html#neutrality"><i class="fa fa-check"></i><b>2.7</b> Neutrality</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="belief.html"><a href="belief.html"><i class="fa fa-check"></i><b>3</b> Belief</a>
<ul>
<li class="chapter" data-level="3.1" data-path="belief.html"><a href="belief.html#beliefsinterests"><i class="fa fa-check"></i><b>3.1</b> Beliefs and Interests</a></li>
<li class="chapter" data-level="3.2" data-path="belief.html"><a href="belief.html#mapslegends"><i class="fa fa-check"></i><b>3.2</b> Maps and Legends</a></li>
<li class="chapter" data-level="3.3" data-path="belief.html"><a href="belief.html#stubbie"><i class="fa fa-check"></i><b>3.3</b> Belief and Stubbornness</a></li>
<li class="chapter" data-level="3.4" data-path="belief.html"><a href="belief.html#given"><i class="fa fa-check"></i><b>3.4</b> Taking As Given</a></li>
<li class="chapter" data-level="3.5" data-path="belief.html"><a href="belief.html#block"><i class="fa fa-check"></i><b>3.5</b> Blocking Belief</a></li>
<li class="chapter" data-level="3.6" data-path="belief.html"><a href="belief.html#questions"><i class="fa fa-check"></i><b>3.6</b> Questions and Conditional Questions</a></li>
<li class="chapter" data-level="3.7" data-path="belief.html"><a href="belief.html#mychanges"><i class="fa fa-check"></i><b>3.7</b> A Million Dead End Streets</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="belief.html"><a href="belief.html#mecorrect"><i class="fa fa-check"></i><b>3.7.1</b> Correctness</a></li>
<li class="chapter" data-level="3.7.2" data-path="belief.html"><a href="belief.html#meimpractical"><i class="fa fa-check"></i><b>3.7.2</b> Impractical Propositions</a></li>
<li class="chapter" data-level="3.7.3" data-path="belief.html"><a href="belief.html#threeway"><i class="fa fa-check"></i><b>3.7.3</b> Choices with More Than Two Options</a></li>
<li class="chapter" data-level="3.7.4" data-path="belief.html"><a href="belief.html#meties"><i class="fa fa-check"></i><b>3.7.4</b> Hard Times and Close Calls</a></li>
<li class="chapter" data-level="3.7.5" data-path="belief.html"><a href="belief.html#modalupdate"><i class="fa fa-check"></i><b>3.7.5</b> Updates and Modals</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="belief.html"><a href="belief.html#usc"><i class="fa fa-check"></i><b>3.8</b> Ross and Schroeder’s Theory</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="knowledge.html"><a href="knowledge.html"><i class="fa fa-check"></i><b>4</b> Knowledge</a>
<ul>
<li class="chapter" data-level="4.1" data-path="knowledge.html"><a href="knowledge.html#structure"><i class="fa fa-check"></i><b>4.1</b> Knowledge and Practical Interests</a></li>
<li class="chapter" data-level="4.2" data-path="knowledge.html"><a href="knowledge.html#theoreticalknowledge"><i class="fa fa-check"></i><b>4.2</b> Theoretical Knowledge</a></li>
<li class="chapter" data-level="4.3" data-path="knowledge.html"><a href="knowledge.html#knowledge-and-closure"><i class="fa fa-check"></i><b>4.3</b> Knowledge and Closure</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="knowledge.html"><a href="knowledge.html#andelim"><i class="fa fa-check"></i><b>4.3.1</b> Single Premise Closure</a></li>
<li class="chapter" data-level="4.3.2" data-path="knowledge.html"><a href="knowledge.html#andintro"><i class="fa fa-check"></i><b>4.3.2</b> Multiple Premise Closure</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="knowledge.html"><a href="knowledge.html#closuresummary"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inquiry.html"><a href="inquiry.html"><i class="fa fa-check"></i><b>5</b> Inquiry</a>
<ul>
<li class="chapter" data-level="5.1" data-path="inquiry.html"><a href="inquiry.html#settling"><i class="fa fa-check"></i><b>5.1</b> Starting and Settling</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="inquiry.html"><a href="inquiry.html#sensitiveinquiry"><i class="fa fa-check"></i><b>5.1.1</b> Sensitivity Chasing</a></li>
<li class="chapter" data-level="5.1.2" data-path="inquiry.html"><a href="inquiry.html#rulesinquiry"><i class="fa fa-check"></i><b>5.1.2</b> Rules</a></li>
<li class="chapter" data-level="5.1.3" data-path="inquiry.html"><a href="inquiry.html#understandinginquiry"><i class="fa fa-check"></i><b>5.1.3</b> Understanding</a></li>
<li class="chapter" data-level="5.1.4" data-path="inquiry.html"><a href="inquiry.html#defraginquiry"><i class="fa fa-check"></i><b>5.1.4</b> Defragmentation</a></li>
<li class="chapter" data-level="5.1.5" data-path="inquiry.html"><a href="inquiry.html#rawlsinquiry"><i class="fa fa-check"></i><b>5.1.5</b> Public Reason</a></li>
<li class="chapter" data-level="5.1.6" data-path="inquiry.html"><a href="inquiry.html#friedmaninquiry"><i class="fa fa-check"></i><b>5.1.6</b> Possible Responses</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="inquiry.html"><a href="inquiry.html#irtinquiry"><i class="fa fa-check"></i><b>5.2</b> Using Knowledge in Inquiry</a></li>
<li class="chapter" data-level="5.3" data-path="inquiry.html"><a href="inquiry.html#independence"><i class="fa fa-check"></i><b>5.3</b> Independence</a></li>
<li class="chapter" data-level="5.4" data-path="inquiry.html"><a href="inquiry.html#doublecheck"><i class="fa fa-check"></i><b>5.4</b> Double Checking</a></li>
<li class="chapter" data-level="5.5" data-path="inquiry.html"><a href="inquiry.html#need"><i class="fa fa-check"></i><b>5.5</b> The Need to Inquire</a></li>
<li class="chapter" data-level="5.6" data-path="inquiry.html"><a href="inquiry.html#realism"><i class="fa fa-check"></i><b>5.6</b> Inquiry Realism</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ties.html"><a href="ties.html"><i class="fa fa-check"></i><b>6</b> Ties</a>
<ul>
<li class="chapter" data-level="6.1" data-path="ties.html"><a href="ties.html#frankielee"><i class="fa fa-check"></i><b>6.1</b> An Example</a></li>
<li class="chapter" data-level="6.2" data-path="ties.html"><a href="ties.html#tiesresponse"><i class="fa fa-check"></i><b>6.2</b> Responding to the Challenge, Quickly</a></li>
<li class="chapter" data-level="6.3" data-path="ties.html"><a href="ties.html#backearth"><i class="fa fa-check"></i><b>6.3</b> Back to Earth</a></li>
<li class="chapter" data-level="6.4" data-path="ties.html"><a href="ties.html#supermarketquestions"><i class="fa fa-check"></i><b>6.4</b> I Have Questions</a></li>
<li class="chapter" data-level="6.5" data-path="ties.html"><a href="ties.html#satisfied"><i class="fa fa-check"></i><b>6.5</b> You’ll Never Be Satisfied (If You Try to Maximise)</a></li>
<li class="chapter" data-level="6.6" data-path="ties.html"><a href="ties.html#deliberationcosts"><i class="fa fa-check"></i><b>6.6</b> Deliberation Costs and Infinite Regresses</a></li>
<li class="chapter" data-level="6.7" data-path="ties.html"><a href="ties.html#ignorancebliss"><i class="fa fa-check"></i><b>6.7</b> Ignorance is Bliss</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="changes.html"><a href="changes.html"><i class="fa fa-check"></i><b>7</b> Changes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="changes.html"><a href="changes.html#overview"><i class="fa fa-check"></i><b>7.1</b> Overview of Replies</a></li>
<li class="chapter" data-level="7.2" data-path="changes.html"><a href="changes.html#gettier"><i class="fa fa-check"></i><b>7.2</b> So Long JTB</a></li>
<li class="chapter" data-level="7.3" data-path="changes.html"><a href="changes.html#building"><i class="fa fa-check"></i><b>7.3</b> Making Up Knowledge</a></li>
<li class="chapter" data-level="7.4" data-path="changes.html"><a href="changes.html#das"><i class="fa fa-check"></i><b>7.4</b> Every Theory is Interest-Relative</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ratbel.html"><a href="ratbel.html"><i class="fa fa-check"></i><b>8</b> Rationality</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ratbel.html"><a href="ratbel.html#atomism"><i class="fa fa-check"></i><b>8.1</b> Atomism about Rational Belief</a></li>
<li class="chapter" data-level="8.2" data-path="ratbel.html"><a href="ratbel.html#lockecoin"><i class="fa fa-check"></i><b>8.2</b> Coin Puzzles</a></li>
<li class="chapter" data-level="8.3" data-path="ratbel.html"><a href="ratbel.html#lockegames"><i class="fa fa-check"></i><b>8.3</b> Playing Games</a></li>
<li class="chapter" data-level="8.4" data-path="ratbel.html"><a href="ratbel.html#lockepuzzles"><i class="fa fa-check"></i><b>8.4</b> Puzzles for Lockeans</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="ratbel.html"><a href="ratbel.html#lockearb"><i class="fa fa-check"></i><b>8.4.1</b> Arbitrariness</a></li>
<li class="chapter" data-level="8.4.2" data-path="ratbel.html"><a href="ratbel.html#lockecorrect"><i class="fa fa-check"></i><b>8.4.2</b> Correctness</a></li>
<li class="chapter" data-level="8.4.3" data-path="ratbel.html"><a href="ratbel.html#lockemoore"><i class="fa fa-check"></i><b>8.4.3</b> Moorean Paradoxes</a></li>
<li class="chapter" data-level="8.4.4" data-path="ratbel.html"><a href="ratbel.html#closure"><i class="fa fa-check"></i><b>8.4.4</b> Closure and the Lockean Theory</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ratbel.html"><a href="ratbel.html#solving"><i class="fa fa-check"></i><b>8.5</b> Solving the Challenges</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="ratbel.html"><a href="ratbel.html#coins"><i class="fa fa-check"></i><b>8.5.1</b> Coins</a></li>
<li class="chapter" data-level="8.5.2" data-path="ratbel.html"><a href="ratbel.html#games"><i class="fa fa-check"></i><b>8.5.2</b> Games</a></li>
<li class="chapter" data-level="8.5.3" data-path="ratbel.html"><a href="ratbel.html#arbitrariness"><i class="fa fa-check"></i><b>8.5.3</b> Arbitrariness</a></li>
<li class="chapter" data-level="8.5.4" data-path="ratbel.html"><a href="ratbel.html#moore"><i class="fa fa-check"></i><b>8.5.4</b> Moore</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="evidence.html"><a href="evidence.html"><i class="fa fa-check"></i><b>9</b> Evidence</a>
<ul>
<li class="chapter" data-level="9.1" data-path="evidence.html"><a href="evidence.html#evpuzzle"><i class="fa fa-check"></i><b>9.1</b> A Puzzle About Evidence</a></li>
<li class="chapter" data-level="9.2" data-path="evidence.html"><a href="evidence.html#simplesolution"><i class="fa fa-check"></i><b>9.2</b> A Simple, but Incomplete, Solution</a></li>
<li class="chapter" data-level="9.3" data-path="evidence.html"><a href="evidence.html#radicalinterpretation"><i class="fa fa-check"></i><b>9.3</b> The Radical Interpreter</a></li>
<li class="chapter" data-level="9.4" data-path="evidence.html"><a href="evidence.html#globalgame"><i class="fa fa-check"></i><b>9.4</b> Risk-Dominant Equilibria</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="evidence.html"><a href="evidence.html#cvdproof"><i class="fa fa-check"></i><b>9.4.1</b> The Dominance Argument for Risk-Dominant Equilibria</a></li>
<li class="chapter" data-level="9.4.2" data-path="evidence.html"><a href="evidence.html#perfectri"><i class="fa fa-check"></i><b>9.4.2</b> Making One Signal Precise</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="evidence.html"><a href="evidence.html#evsolution"><i class="fa fa-check"></i><b>9.5</b> Objections and Replies</a></li>
<li class="chapter" data-level="9.6" data-path="evidence.html"><a href="evidence.html#cutelim"><i class="fa fa-check"></i><b>9.6</b> Evidence, Knowledge and Cut-Elimination</a></li>
<li class="chapter" data-level="9.7" data-path="evidence.html"><a href="evidence.html#basic"><i class="fa fa-check"></i><b>9.7</b> Basic Knowledge and Non-Inferential Knowledge</a></li>
<li class="chapter" data-level="9.8" data-path="evidence.html"><a href="evidence.html#neta"><i class="fa fa-check"></i><b>9.8</b> Holism and Defeaters</a></li>
<li class="chapter" data-level="9.9" data-path="evidence.html"><a href="evidence.html#weakness"><i class="fa fa-check"></i><b>9.9</b> Epistemic Weakness</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="power.html"><a href="power.html"><i class="fa fa-check"></i><b>10</b> Power</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Made with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Knowledge</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inquiry" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Inquiry<a href="inquiry.html#inquiry" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The next three chapters are primarily defensive; they are responding to the three objections to IRT that seem to me most serious. But they aren’t just defensive. I’m not just saying why the theory from the chapters to date is immune to these arguments.; I’m also developing the theory. That’s especially true in this chapter, which is why it is first. So what are these objections.</p>
<p>The first is what I’ll call the <em>objection from double checking</em>. As Jessica Brown <span class="citation">(<a href="references.html#ref-Brown2008" role="doc-biblioref">2008</a>)</span> argued, there are plenty of cases where intuitively a person knows that <em>p</em>, but should check whether <em>p</em> is true. This seems to be a problem for IRT, since it is motivated by the thought that what’s known is an appropriate starting point in inquiry. And intuitively it’s very weird to have an inquiry into <em>p</em>, when the inquirer is in a position to simply say <em>p</em>, <em>therefore</em> <em>p</em>. I used to think that in these cases the defender of IRT would have to either say that they are not really cases of knowledge, or not really cases of appropriate inquiry. And I tried both options at various times, without much success. But I now think this is wrong. It is possible to properly conduct an inquiry into <em>p</em>, even when one knows that <em>p</em>, and even when knowledge provides appropriate starting points for inquiry. That’s because it is often appropriate to deliberately restrict oneself in inquiry, and use fewer resources than are otherwise available. This chapter sets out this response to the objection from double checking.</p>
<p>The second is what I’ll call the <em>objection from close calls</em>. As Alex Zweber <span class="citation">(<a href="references.html#ref-Zweber2016" role="doc-biblioref">2016</a>)</span> and, separately, Charity Anderson and John Hawthorne <span class="citation">(<a href="references.html#ref-AndersonHawthorne2019a" role="doc-biblioref">2019a</a>)</span> showed, some simple versions of IRT say implausible things about cases where a person is choosing between very similar options. Now it turns out my preferred version of IRT doesn’t say the particular implausible thing they were accusing IRT of. But that’s little consequence, since the theory looks like it says a different, but equally implausible thing. They thought IRT implied weird closure failures, and my version doesn’t do that, but at the pain of having weird kinds of scepticism. So the objection is a pressing one. The argument that IRT has weird consequences (either closure failures or scepticism) relies on the thought that choosers should maximise expected utility. And my response is going to be that choosers should not maximise expected utility. That might sound like an absurdly radical view, since expected utility theory is at the heart of all contemporary decision theory. But when we look at what it says in the very cases that raise problems for IRT - these close call cases - it looks particularly implausible. A better view is that choosers should adopt a choice procedure that maximises expected utility given their limitations. In close call cases, typically the best procedure by that standard will be to pick arbitrarily; the expected loss of expected utility is less than the effort it would take to maximise expected utility. And given this picture of rational choice, IRT does not entail anything weird in these cases. I’ll say much more about this in chapter <a href="ties.html#ties">6</a>.</p>
<p>The third is what I’ll call the <em>objection from abominable conjunctions</em>. This is the IRT-equivalent of the blank stare objection to modal realism. Many people find it simply implausible that knowledge could depend on something like interests, which are not relevant to the truth of what is purportedly known. And the defender of IRT owes a reply to this widespread feeling. Part of my reply came back in chapter <a href="background.html#background">1</a>. I think this feeling is a result of being in a very strange place in the history of epistemology, where the focus is on fallibilist, interest-invariant, concepts. But we can do better than that. It is hard to articulate the intuition behind the unhappiness with IRT without lapsing into the JTB theory of knowledge. And most plausible solutions to the problems with the JTB theory end up introducing kinds of interest-relativity for independent reasons. I’ll go over these responses in chapter <a href="changes.html#changes">7</a>.</p>
<p>So those are the three objections I’m going to spend a lot of time on. There are three other classes of objection I’m not going to spend much time on.</p>
<p>The first class are objections to IRT that assume that knowledge changes when and only when one is in a ‘high stakes’ situation. Since I don’t assume that, those objections don’t raise problems for my version of IRT.</p>
<p>The second class are objections to IRT that assume that some parts of epistemology are interest-invariant, while some are interest-relative. I used to endorse such a theory, but I don’t any more. This book defends a global interest-relativism where knowledge, belief, rationality and evidence are all interest-relative (in different ways). So these objections don’t raise problems for my version of IRT either.</p>
<p>The third class are objections to IRT that only apply to versions of IRT that add on an opposition to contextualism or relativism. With this addition, IRT becomes what has been called <em>interest-relative invariantism</em>, or IRI. And it’s what I’ve defended in the past. And, to be honest, it’s still what I mostly believe. But I’m not going to defend that stronger theory here, just the claim that knowledge is interest-relative. If you want to understand that theory in a contextualist or relativist way, go right ahead.</p>
<p>The argument that if IRT is true, then either a contextualist or relativist version of it is true, turns on some plausible intuitions about extensions of Anisa’s case. Imagine that Anisa knows that her friend Etienne has read the same history book as her, and has just as good a memory as she does, and otherwise has in some intuitive sense the same evidence as her about the Battle of Agincourt. But Etienne is not playing the Red-Blue game, she’s just on the bus to work. On the most straightforward version of IRT, Etienne knows that the Battle of Agincourt was in 1415. Now Anisa can’t know that Etienne knows that, since that would entail that Battle of Agincourt was indeed in 1415. But plausibly, Anisa does know that Etienne might know when the Battle was, and she knows that if it was in 1415, Etienne knows this. The contextualist intuition is that Anisa would be more inclined to deny that Etienne knows this. After all, Etienne is just as well placed as Anisa herself is, and she doesn’t know when the battle is. The relativist intuition is that if Etienne were to say <em>I know the Battle of Agincourt was in 1415</em> (an odd thing to say on the bus I guess), Anisa would judge that as false, for much the same reason. Personally, I think these intuitions are not that strong, and that they are driven by the kind of theoretical intuitions that I’ll argue in chapter <a href="changes.html#changes">7</a> are misguided. But if you want to save one or both of these intuitions, you’ll probably want to adopt either a contextualist or a relativist version of IRT, or perhaps even both a contextualist and a relativist version. I’ll leave those arguments for another book, since I’m not taking a stand on them. Defending IRT is enough work without diving into debates about contextualism and relativism.</p>
<div id="settling" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Starting and Settling<a href="inquiry.html#settling" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>At the heart of Jane Friedman’s influential picture of inquiry are a number of distinctive attitudes. <span class="citation">(<a href="references.html#ref-Friedman2017" role="doc-biblioref">Friedman 2017</a>, <a href="references.html#ref-Friedman2019a" role="doc-biblioref">2019b</a>, <a href="references.html#ref-Friedman2019b" role="doc-biblioref">2019a</a>, <a href="references.html#ref-Friedman2020" role="doc-biblioref">2020</a>)</span> To be inquiring into some question, she argues, is to have a <em>questioning attitude</em> towards that question. That’s to say, she does not identify inquiry with particular actions, or at least with particular bodily movements. An actor might mimic the movements an inquirer makes without actually inquiring; a genuine inquirer might be sitting in an armchair synthesizing their evidence. So particular movements are neither sufficient nor necessary for real inquiry. Rather, inquiry is a state of mind, a questioning state of mind.</p>
<p>The contrast to having a questioning attitude is having a <em>settled</em> attitude.<a href="#fn33" class="footnote-ref" id="fnref33"><sup>33</sup></a> Like the position I’ve adopted here, Friedman holds that to believe something is to treat the question of whether it is true as being affirmatively settled. And this is deeply related to inquiry. Typically things are settled as the result of inquiry. Also typically, one does not inquire into something one has settled. And, she holds, if one does inquire into something one has settled, this is a kind of mistake. It is incoherent to both have a questioning and a settled attitude towards the same question. I’m going to disagree with this last bit, while mostly agreeing with the broad picture.</p>
<p>The main difference between that picture and the picture of inquiry I’m using concerns where beliefs go in inquiry. I think that treating something as settled is most fundamentally about willingness to use it as the beginning of a new inquiry. The essential feature of belief is that it starts inquiry, not that it ends inquiry. I used to think that this was only a difference of emphasis, and a pretty minor one at that. After all, beliefs are typically the outputs of one inquiry and then serve as inputs to another; whether one takes one or other of these roles to be more fundamental seems like a pretty esoteric question. But I’ve come to think that actually quite a bit turns on it. If you think beliefs are fundamentally the things that inquiry start with, then there is a little gap in the argument that one should not inquire into what one already believes.</p>
<p>That argument, the one to the conclusion that one should not inquire into what one already believes, seems pretty simple. Assume one believes that <em>p</em> and is inquiring into the question <em>p?</em>. Our theory is that beliefs are appropriate starting points for inquiry, so it looks like this one should end pretty quickly. One can just argue <em>p</em>, therefore <em>p</em>, and close the inquiry. If the inquiry stays open longer than that, one is doing it wrong.</p>
<p>And this looks like a pretty strong argument for a conclusion that a number of people have reached via different routes.<a href="#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>.</p>
<blockquote>
<p>If one knows the answer to some question at some time then one ought not to be investigating that question, or inquiring into it further … at that time. <span class="citation">(<a href="references.html#ref-Friedman2017" role="doc-biblioref">Friedman 2017, 131</a>)</span></p>
</blockquote>
<blockquote>
<p>There is something to be said for the claim that the person who knows they have turned the coffee pot off should not be going back to check. <span class="citation">(<a href="references.html#ref-HawthorneStanley2008" role="doc-biblioref">Hawthorne and Stanley 2008</a> ,587)</span></p>
</blockquote>
<blockquote>
<p>Any such cases [of believing while inquiring] involve peculiarities (such as irrationality or fragmentation). <span class="citation">(<a href="references.html#ref-McGrath2021" role="doc-biblioref">McGrath 2021</a> ,482n37)</span></p>
</blockquote>
<p>So how could that argument fail? It could fail if there are reasons for adopting constraints on an inquiry. If there are reasons to not use all the tools at our disposal, there could be cases where an inquiry into <em>p</em> gets started, and we have reasons not to just say <em>p</em>, therefore <em>p</em>. At this level of abstraction, this doesn’t sound very likely. It seems at first like there should be something like a principle of total evidence for inquiry, saying that you can use whatever tools, whatever evidence, you have to hand. But such a principle turns out to be false.</p>
<p>To warm up to this, consider an analogy to legal inquiries. There we are all familiar with the idea that some evidence might be inadmissible in some inquiries. Now the reasons for this are typically not epistemic. It’s rather that we think the system as a whole will be more just if some kinds of evidence are excluded from some inquiries. And that looks a bit different to the situation where an individual inquirer is just trying to find what’s true. But we’ll see that the analogy here is not quite as bad as it first looks.</p>
<p>In the rest of this section, I’ll go over five kinds of cases where one can sensibly inquire into what one already knows. I don’t think any of these examples constitute knock-down proofs, and for reasons I’ll get to later in the chapter, I don’t really need them to. But it is helpful to see the range of cases where inquiry into what one knows is useful.</p>
<div id="sensitiveinquiry" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Sensitivity Chasing<a href="inquiry.html#sensitiveinquiry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Guido Melchior <span class="citation">(<a href="references.html#ref-Melchior2019" role="doc-biblioref">2019</a>)</span> argues that the point of <em>checking</em> is to establish a sensitive belief in the checked proposition. To motivate this, think about the following case. Florian has just weighed out the coffee beans for his morning pot of coffee. Naturally he uses the best scales he has for this purpose; it’s important to get the coffee right. He starts wondering whether his scales have recently stopped being reliable. What does he do next? Here’s one thing he doesn’t do. He doesn’t look at the beans on the scale, note that the scale says 24g, note that he knows they are 24g (via that excellent scale), and conclude that the scale is still working. That’s no good at all; he has to use some other scale to check this one. This is like the Problem of Easy Knowledge <span class="citation">(<a href="references.html#ref-Cohen2002" role="doc-biblioref">Cohen 2002</a>)</span>, but note that it doesn’t rely on the scale being a source of basic knowledge. Florian might have lots of independent evidence that the scale is good; it’s from a good manufacturer and has been producing plausible results for a while. Still, if he wants to check it, he has to use something else. And here’s the part that seems most surprising to me. Add to the story that he has a backup scale, one that he thinks is pretty good but not as good as his best scale. It’s fine to use the backup scale to check the main scale, and not fine to use the scale to check itself. The best explanation for this is that checking requires sensitivity. Using the scale to test itself is a method that isn’t sensitive to whether the scale is working. Using some other scale, even a less reliable one, to check whether it is working, is at least somewhat sensitive. And checking is, at least in part, a matter of <em>sensitivity chasing</em>. And the best explanation of why checking is a good thing to do is that often sensitivity chasing is sensible, since it’s good to have sensitive beliefs.</p>
<p>So sensitivity chasing is perfectly acceptable goal in inquiry. One might inquire into <em>p</em> for the purpose of making one’s belief in <em>p</em> more sensitive. Now assume, as most epistemologists believe, that one can know <em>p</em> even if one’s belief is insensitive in various ways. One can know <em>p</em> even if one would still believe <em>p</em> were <em>p</em> false. In that case, sensitivity chasing might be a worthwhile goal in inquiry. It is, I think, the main goal in the kind of inquiry we call checking. But inquiring into <em>p</em> by saying <em>p</em> therefore <em>p</em> will not increase one’s sensitivity to whether <em>p</em> is true. So it’s worthwhile to not allow that move in the inquiry, if the aim is to increase sensitivity.</p>
<p>There are other examples that show the difference between knowing and checking. Slightly modifying an example from Frank Jackson <span class="citation">(<a href="references.html#ref-Jackson1987" role="doc-biblioref">1987</a>)</span>, imagine that someone wants to know what _The Age_said was the result of last night’s game. One way to learn what <em>The Age</em> said would be to look up the result in <em>The Guardian</em>, and use one’s background knowledge that they both report the same (correct) result. That’s a way to come to know what <em>The Age</em> said. But it’s not a way to check what <em>The Age</em> said. And it’s not a way to check because had <em>The Age</em> said anything different, you wouldn’t have known. That’s a kind of insensitivity. It’s an insensitivity that’s consistent with knowledge; one can know what a newspaper says by knowing the truth and that it reports the truth. But it is one that is removed by proper checking. So checking aims for sensitivity that goes beyond belief, and beyond knowledge. And given that checking, i.e., chasing this kind of sensitivity, is rational, so is inquiring into what one knows.</p>
</div>
<div id="rulesinquiry" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Rules<a href="inquiry.html#rulesinquiry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It’s hard to always be perfectly rational. Sometimes it makes sense to not think too hard about things where getting the right answer would be quite literally more trouble than it’s worth. I’ll have much more to say about this point in chapter <a href="ties.html#ties">6</a>, where I make much of this insight from Frank Knight.</p>
<blockquote>
<p>It is evident that the rational thing to do is to be irrational, where deliberation and estimation cost more than they are worth. <span class="citation">(<a href="references.html#ref-Knight1921" role="doc-biblioref">Knight 1921, 67fn1</a>)</span></p>
</blockquote>
<p>Knight is interested in the case where the rational thing to do is not inquire when inquiry would have minimal gains. But there is another case that is more relevant here. Sometimes it is worth having a simple rule that says <em>Always inquire in these situations</em>, rather than having a meta-inquiry into whether inquiry is worthwhile right now. To make this a little less abstract, it might be worthwhile always checking that the door is locked when one closes it, even if one frequently knows that one has just locked the door. As <span class="citation">Hawthorne and Srinivasan (<a href="references.html#ref-HawthorneSrinivasan2013" role="doc-biblioref">2013</a>)</span> point out, given the non-luminosity of evidence and knowledge, a simple rule like this might do better any other realistic rule.</p>
<p>Often following rules about when to inquire will be part of one’s professional responsibilities. I presented an example like this in chapter 7 of <em>Normative Externalism</em> - an inspector who is sent to do a random check of an establishment he had checked just a few days before. He knows everything is working well; he just checked it! But it’s his job to check, and it’s good to have random spot checks on top of regular checks, so it’s good to run this inquiry. That’s true even though the inspector knows how it will end.</p>
</div>
<div id="understandinginquiry" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Understanding<a href="inquiry.html#understandinginquiry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There is a famous puzzle about moral testimony. Something seems off about a person who simply believes moral principles on the basis of testimony, even from a trusted testifier. It’s odd to convert to vegetarianism simply because someone you trust says that’s what morality requires. There is also a famous answer to this puzzle, due to Alison Hills <span class="citation">(<a href="references.html#ref-Hills2009" role="doc-biblioref">2009</a>)</span>. (There are other answers too, including ones that deny the puzzle exists. But to avoid going down too many rabbit holes, I’m going to assume for now the answer Hills is correct.) Hills says that moral testimony can give us moral knowledge, like any kind of testimony can provide knowledge, but it can’t provide understanding. What’s weird about the person who becomes a vegetarian on testimonial grounds alone is that the can’t explain their actions, since they don’t know why they are acting this way.</p>
<p>Beyond moral testimony, there seem to be many everyday cases of knowledge without understanding. One can know that Franz Ferdinand was assassinated in Sarajevo on June 28, 1914, without knowing why that happened. Or, indeed, one can know why one part of that is true, e.g., why it was that <em>Franz Ferdinand</em> was assassinated in Sarajevo on June 28, 1914, without knowing why he was assassinated <em>in Sarajevo</em>, or <em>on June 28, 1914</em>. Given those facts, it is possible to seek understanding of something that one already knows.</p>
<p>In many cases, but not all, the search for understanding will look like a somewhat different inquiry to the search for knowledge. If one wants to know why Franz Ferdinand was assassinated <em>in Sarajevo</em>, one will inquire into the role that city plays in the history of relations between Austria-Hungary and Serbia. That will be a different kind of inquiry to determining whether the assassination really happened. But in the moral case things aren’t this clear. Imagine again our person who hears from a trusted source that meat eating is wrong, but doesn’t understand why this is so. They should do some moral inquiry. And the inquiry will look, as far as I can see, very similar to the inquiry they will do in case they are working out whether meat eating is wrong. That is, it will look just like an inquiry into whether meat eating is wrong.</p>
<p>I think the best way to systematise things here is to take appearances at face value. Even once one is convinced meat eating is in fact wrong, if one doesn’t know why it is, one will continue to inquire into the morality of meat eating. And this inquiry is justified by the aim of coming to understand the wrongness of meat eating.</p>
</div>
<div id="defraginquiry" class="section level3 hasAnchor" number="5.1.4">
<h3><span class="header-section-number">5.1.4</span> Defragmentation<a href="inquiry.html#defraginquiry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall Professor Paresseux from subsection <a href="knowledge.html#andintro">4.3.2</a>. He’s told that the visiting speaker this week is his old graduate school colleague Professor Assidue. But he puts no effort into remembering this fact, and it slips from the front of his mind. The talk is approaching, and Paresseux wonders to himself, who’s talking to us this afternoon? So he Googles the department talk schedule, sees that it is Assidue, and then says to himself “Ah, I knew that, I saw the email the other day.”</p>
<p>It is very hard to fit the category of information that has ‘slipped one’s mind’ into familiar epistemological categories. I think we should say that Paresseux is correct, and he did indeed know the answer to his inquiry before he started looking. After all, he could have retrieved the information by simply thinking hard about what had happened this week. And the best explanation for why that’s possible is that he did still know that Professor Assidue would be the speaker. But I also think it made sense for him to conduct an inquiry into this thing that he knew. It’s much easier to Google something than to trawl one’s memory for the answer. More reliable too. So this looks like a sensible inquiry for him to have conducted.</p>
<p>Following Andy Egan <span class="citation">(<a href="references.html#ref-Egan2008" role="doc-biblioref">2008</a>)</span>, I think we should think of this as a case where Paresseux’s mind is ‘fragmented’, in the sense of <span class="citation">Lewis (<a href="references.html#ref-Lewis1982c" role="doc-biblioref">1982</a>)</span> and <span class="citation">Stalnaker (<a href="references.html#ref-Stalnaker1984" role="doc-biblioref">1984</a>)</span>. There is a part that contains the information about who the speaker is, but that part isn’t at the front of his attention, so he doesn’t act on it. But it is a part of him; he knows that stuff. Still, it is better to conduct an inquiry, i.e., a Google search, than to rely on this knowledge. So it is rational to inquire into something one knows.</p>
</div>
<div id="rawlsinquiry" class="section level3 hasAnchor" number="5.1.5">
<h3><span class="header-section-number">5.1.5</span> Public Reason<a href="inquiry.html#rawlsinquiry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One unfortunate position an inquirer can find themselves in is knowing something is true, even understanding why it is true, and being unable to convince anyone of their result. At this point one needs more reasons, but where to find them? Often, the way to find them will be to do what anyone else would do if they were trying to find out if the thing itself were true. Here are two such examples, drawn from rather different parts of philosophy.</p>
<p>Michael Strevens <span class="citation">(<a href="references.html#ref-Strevens2020" role="doc-biblioref">2020</a>)</span> argues that the effectiveness of science in the last 350 years has come because scientists have adopted an “iron rule”: <em>only empirical evidence counts</em>. There are any number of ways one might come to rationally believe a scientific theory other than evidence. It might follow from broadly metaphysical principles one holds (at least in the early modern sense of metaphysical), it might be more elegant than any other theory, it might promise to unify seemingly disparate phenomena. But if you want to convince the scientific community, meaning convince both the collective community and most of the scientists who make it up, you need data. So you go looking for data, even for theories you know are true on non-empirical grounds. Strevens thinks this is individually irrational, but collectively for the best. It’s irrational for any one person to have just one way to come to believe things. But by incentivising the search for data in this way, we’ve collectively created an institution that has taken the measure of the world in ways previously unimaginable. There is something else valuable about data - it’s available, at least in principle, to everyone. So even if you can’t recreate my metaphysical intuitions, you can rerun my experiments. The iron rule doesn’t just lead to more measurements being taken, it imposes a kind of public reason constraint on science. Only evidence that everyone can accept as evidence, and indeed that they could (at least in theory) create for themselves, counts.</p>
<p>This way of putting the point should remind us of an important strand in contemporary political philosophy, namely that political rules should satisfy a <em>public reason</em> constraint. As Jonathan Quong puts it</p>
<blockquote>
<p>Public reason requires that the moral or political rules that regulate our common life be, in some sense, justifiable or acceptable to all those persons over whom the rules purport to have authority. <span class="citation">(<a href="references.html#ref-Quong2017" role="doc-biblioref">Quong 2018</a>)</span></p>
</blockquote>
<p>Now as a matter of fact, we haven’t had as much uptake of this meta-rule in politics as in science. But we can imagine a society where there is, in practice, a kind of public reason constraint. If you want your favorite rule to be part of the regulation of society, you have to come up with a justification of it that satisfies this constraint. In such a society, there will be people who have idiosyncratic ideas for rules that would be good rules for the community, ideas that they don’t have public justifications for. In practice, the vast majority of these ideas will be bad ones. But some of them will not be. Indeed, a handful will even know that their ideas are good. Still, if this knowledge comes via idiosyncratic sources, they will need to come up with more public reasons if they want to see their rule implemented. And as I suggested in the previous subsection, the way to find reasons for a moral claim is generally to inquire into whether that claim is true. Or, at least, to act like that’s what one is doing.</p>
</div>
<div id="friedmaninquiry" class="section level3 hasAnchor" number="5.1.6">
<h3><span class="header-section-number">5.1.6</span> Possible Responses<a href="inquiry.html#friedmaninquiry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If this was a paper dedicated to proving that it is rational to inquire into what one knows, at this stage I’d have to show that a philosopher who denies that is ever rational has no good story to tell about these five cases. And that would be a lot to show, since actually there is plenty that such a philosopher could say. They could deny that the inquiries are indeed rational. They could deny that the inquirers in question really do know the thing they are inquiring into, perhaps using IRT to back up that denial. They could deny that these are real inquiries, as opposed to some kind of ersatz inquiry. Or they could deny that this is really an inquiry into the very thing known, as opposed to an inquiry into some related proposition, like what the causal history of that thing was. And they wouldn’t even have to choose between these four; they could mix-and-match to deal with the putative counterexamples.</p>
<p>At the end of the day, I don’t think these responses will cover all the cases. But it would be a massive digression to defend that claim, and it isn’t necessary for what’s going to happen in the rest of this chapter. All I need is that there are people who very much look like they are conducting rational, genuine inquiries into things they already know. If there is a subtle way of explaining away that appearance, that won’t matter for the story that’s to come, since such subtleties will end up being good news for my side of the debate about IRT. The worry we’re building up to is that IRT has no good explanation of what’s happening in cases where someone seems to rationally, genuinely inquire into something they already know. If there are in fact no such cases, that can’t be a problem!</p>
<p>One reason for thinking that some of these cases will work is that there is a fairly general recipe for constructing the cases. It’s due to Elise Woodard <span class="citation">(<a href="references.html#ref-Woodard2021" role="doc-biblioref">2020</a>)</span> and (independently) Arienne Falbo <span class="citation">(<a href="references.html#ref-Falbo2021" role="doc-biblioref">2021</a>)</span>. Start with the following two assumptions. First, inquiry is not just about collecting knowledge, but generally about improving one’s epistemic position. Second, given fallibilism, one can know <em>p</em> but have a sub-optimal epistemic position. So one can know <em>p</em>, but (rationally) want to improve one’s epistemic position with respect to <em>p</em>. And if one acts to address that want, one will be inquiring into what one knows, and doing so rationally. Given IRT you should worry about whether every step in the last few sentences really does follow from the ones before it. But I suspect the general picture is right, especially, as <span class="citation">Melchior (<a href="references.html#ref-Melchior2019" role="doc-biblioref">2019</a>)</span> stresses, in checks aimed at increasing sensitivity.</p>
<p>Looking ahead a little, the primary aim of the rest of the chapter will be to defuse some potential counterexamples to IRT that involve someone rationally inquiring, especially checking, what they know. And my response will be disjunctive. Either inquiry solely aims at knowledge, or it does not. If inquiry does solely aim at knowledge, appearances in this cases are deceiving, and the inquiry is not in fact rational. If, as I think, inquiry does not solely aim at knowledge, then the cases are not in fact counterexamples to IRT.</p>
</div>
</div>
<div id="irtinquiry" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Using Knowledge in Inquiry<a href="inquiry.html#irtinquiry" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sometimes an inquirer has reasons to deliberately hobble their own inquiry. They have reasons to conduct an inquiry with one hand tied behind their back. Perhaps those reasons come from the social norms of the enterprise they are engaged in, as Strevens suggests. Perhaps those reasons come from the fact that they are sensitivity chasing, as Melchior suggests, and only a restricted inquiry will increase sensitivity. Perhaps those reasons come from the fact that they are trying to follow rules, and the rules do not allow certain kinds of tools to be used. The unifying theme is that sometimes the inquirer wants not just to run an inquiry, but to run it in a particular way.</p>
<p>The core principle in my version of IRT is that someone who uses what they know in inquiry is immune to criticism on the grounds that what they are doing is epistemically risky. Equivalently, they are immune to criticism on the grounds that their premises might be false. That’s compatible with saying that someone can know <em>p</em>, and be properly criticised for using <em>p</em> in inquiry. I motivated that restriction in section <a href="knowledge.html#theoreticalknowledge">4.2</a> by looking at people whose use of <em>p</em> in inquiry can be criticised on relevance grounds. But here we see several more reasons. Someone who has reasons to perform a restricted inquiry, especially someone whose aims can only be realised by conducting a properly restricted inquiry, can be criticised for overstepping those restrictions. That’s fine, and totally consistent with IRT, as long as we pay attention not just to whether someone is being criticised, but why they are being criticised.</p>
<p>It isn’t just my idiosyncratic version of IRT that escapes this criticism. Jeremy Fantl and Matthew McGrath defend a version of IRT that uses the following principle.</p>
<blockquote>
<p>When you know a proposition <em>p</em>, no weaknesses in your epistemic position with respect to <em>p</em>—no weaknesses, that is, in your standing on any truth-relevant dimension with respect to <em>p</em>—stand in the way of <em>p</em> justifying you in having further beliefs. <span class="citation">(<a href="references.html#ref-FantlMcGrath2009" role="doc-biblioref">Fantl and McGrath 2009, 64</a>)</span></p>
</blockquote>
<p>I’m going to come back in section <a href="evidence.html#weakness">9.9</a> to why I don’t quite think that’s right. But my disagreement turns on a fairly small technical point; I’m following Fantl and McGrath’s lead much more than I’m diverging from them. And these examples of properly restricted inquiry show how they too can accept rational inquiry into what one already knows.</p>
<p>Consider a person who is sensitivity chasing; they know <em>p</em> but want to have a more sensitive belief that <em>p</em>. So they conduct an inquiry into <em>p</em>, and reason to themselves <em>p</em>, therefore <em>p</em>. This closes the inquiry. Something has gone wrong. It isn’t bad reasoning; can’t go wrong with identity. And it isn’t that they use something they know as a premise; anything one knows can be used as a premise. It’s that they had an aim that could only be met by a restricted inquiry, and they violated those restrictions. That’s the incoherence here.</p>
<p>There is a way to read Fantl and McGrath’s principle so that this case is a problem for them, but I don’t think it’s the right reading. The sensitivity of one’s belief is, in their terms, part of the strength of one’s epistemic position. So if one’s belief was more sensitive, one wouldn’t have a reason to be chasing sensitivity. So in this case, you might think it’s weakness of epistemic position that’s relevant; the weakness of epistemic position explains why the inquiry is being conducted in the first place. But I don’t think that’s fair. The principle only talks about how inquiry should be conducted, not about whether the inquiry should be conducted. So Fantl and McGrath could say, and I believe should say, that knowledge is compatible with the weakness in one’s epistemic position explaining why an inquiry is in order. It’s just that knowledge is not compatible with weakness of epistemic position preventing the knowledge being used once the inquiry starts.</p>
</div>
<div id="independence" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Independence<a href="inquiry.html#independence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>These reflections on the nature of inquiry help tidy up a loose end from <em>Normative Externalism</em> <span class="citation">(<a href="references.html#ref-Weatherson2019" role="doc-biblioref">Weatherson 2019</a>)</span>. In that book I argued against David Christensen’s Independence principle, but I didn’t offer a fully satisfactory explanation for why the principle should seem plausible. Here’s the principle in question.</p>
<blockquote>
<p><strong>Independence</strong>: In evaluating the epistemic credentials of another’s expressed belief about P, in order to determine how (or whether) to modify my own belief about P, I should do so in a way that doesn’t rely on the reasoning behind my initial belief about P. <span class="citation">(<a href="references.html#ref-Christensen2011" role="doc-biblioref">Christensen 2011, 1–2</a>)</span>.</p>
</blockquote>
<p>This is expressly stated as a principle about disagreement, but it is meant to apply to any kind of higher-order evidence. (This is made clear in “Formulating Independence” <span class="citation">(<a href="references.html#ref-Christensen2019" role="doc-biblioref">Christensen 2019</a>)</span>, which also includes some new thoughts about how Christensen now thinks the principle should be stated.) I argued that this couldn’t be right in general; it gives the wrong results in clear cases, and leads to regresses. But something like it does sound right. It sounds like there should be some kind of true claim in the vicinity. In <em>Normative Externalism</em> I hinted at an inquiry-theoretic proposal about what that nearby truth might be. (See, for example, the response to <span class="citation">Littlejohn (<a href="references.html#ref-Littlejohn2015" role="doc-biblioref">2018</a>)</span>, at the top of page 178.) But I never really spelled it out. Here’s what I now think the right thing to say is. <a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a></p>
<p>Peer disagreement, or really any other kind of higher order evidence, gives a thinker a reason to conduct an inquiry into whether their earlier thinking was correct. And not just that, it gives them reason to conduct an inquiry that is restricted in a particular way. The restriction is that they should not rely on the reasoning from their earlier thinking. Putting those two things together, we get that disagreement about <em>p</em> gives someone who believes <em>p</em> reason to inquire into <em>p</em> using a different approach, any different approach, from what they previously used.</p>
<p>Once we’ve got a principle about reasons, we could try formulating this as a defeasible rule. It’s plausible that one should adopt the defeasible rule of conducting such an inquiry whenever one sees a disagreement, or some other kind of potentially defeating higher-order evidence. And as long as one builds enough into the defeasibility clause, such a rule won’t be subject to the counterexamples I described, or the ones that have caused <span class="citation">Christensen (<a href="references.html#ref-Christensen2019" role="doc-biblioref">2019</a>)</span> to have second thoughts about the right formulation of the rule. After all, every counterexample will naturally fall into the defeasibility clause.</p>
<p>Such a rule could be justified by the observation that it will probably be beneficial in the long run for people like us to adopt it. Double checking isn’t that hard. And it can have a lot of benefits in cases where it makes a difference; even if most of the time it doesn’t. Getting stuck in a bad epistemic picture can have devastating consequences; it’s good to step back from time to time to look if that’s happening to us. And disagreements with peers are a natural trigger for that kind of inquiry. Those same benefits can explain why disagreement, or other kinds of higher-order evidence, give us reason to double check.</p>
<p>But why should one conduct a restricted inquiry here? Given the stakes, we’re trying to work out whether we’ve got ourselves into a bad epistemic state, shouldn’t we through everything we have at the problem? That would be bad, since Independence expressly bars the thinker from using some of the tools at their disposal. It requires them to not do the same kind of inquiry they did before, which presumably was the one they thought best suited to the problem. That’s a big restriction, and needs some justification. I can offer two kinds of justification, not entirely distinct.</p>
<p>The point of having a rule like this, a rule like <em>Double-check your reasoning when a peer disagrees</em>, is to prevent us falling into epistemic states that are local but not global equilibria. The states we’re worried about are ones where any small change will make the epistemic state worse, but large changes will make things better. Picturesquely, we’ve reached the top of a small hill when we want to climb a mountain. We should be somewhere higher, but any step will be downhill. It’s good to not get stuck in places like this, and nudges from friends are a way out.</p>
<p>If we want to check whether we’re in such a bad situation, we want a test that is sensitive to whether we are. That is, we want a test that would say something different if we were in that situation to what it would say if we were doing well. (This is Melchior’s point about the aim of tests.) And just conducting the same inquiry we previously conducted will typically not be sensitive in this way. Or, more precisely, it will be sensitive to something like performance errors, but not competence errors. We need something more sensitive if the aim is to avoid getting stuck in local equilibria, and that requires setting aside the work we’ve previously done.</p>
<p>One of the reasons that local equilibria can be sticky is that we know our way around them well. We know all the ways in which one part of the picture we have supports the other parts. We typically don’t know how to think about other pictures so clearly. We don’t know, don’t see, the ways in which other pictures might ‘hang together’ as well as ours does. We are inevitably going to be biased towards our own ways of thinking. So it’s worthwhile to try to level the playing field, by looking at how things would seem if we didn’t have our own distinctive way of thinking.</p>
<p>None of this is to take back anything I said in <em>Normative Externalism</em>. Disagreement with a peer known to have the same evidence does not give someone a reason to reject a well-formed belief. It gives them a reason to double-check that belief. But, as I’ve been stressing all chapter, one can double-check one’s beliefs, and even one’s knowledge. And that is what should happen here.</p>
<p>Finally, thinking of disagreement as providing a reason to double check provides a nice explanation of one of the harder examples in <em>Normative Externalism</em>, the case of Efrosyni on page 222. She does a calculation, then double checks it by a different technique, then hears that a peer disagrees. What should she do now? I think typically she should do nothing. The disagreement gives her a reason to double check each calculation she did, but she’s already carried out that double check. This is, I think, the intuitively right result. If someone has already double checked their work, they should infer that someone who disagrees is wrong. Perhaps in some rare case they could get reason to double check the ‘combined’ inquiry, consisting of the initial inquiry plus the double check. But that’s rare; usually they should just point out their work.</p>
<p>With this picture of the relationship between knowledge, inquiry, and checking in place, it’s time (at last) to return to potential counterexamples to IRT.</p>
</div>
<div id="doublecheck" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Double Checking<a href="inquiry.html#doublecheck" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An example from Jessica Brown</p>
<blockquote>
<p>A student is spending the day shadowing a surgeon. In the morning he observes her in clinic examining patient A who has a diseased left kidney. The decision is taken to remove it that afternoon. Later, the student observes the surgeon in theatre where patient A is lying anaesthetised on the operating table. The operation hasn’t started as the surgeon is consulting the patient’s notes. The student is puzzled and asks one of the nurses what’s going on:</p>
<p>Student: I don’t understand. Why is she looking at the patient’s records? She was in clinic with the patient this morning. Doesn’t she even know which kidney it is?
Nurse: Of course, she knows which kidney it is. But, imagine what it would be like if she removed the wrong kidney. She shouldn’t operate before checking the patient’s records.</p>
</blockquote>
<p>I think this is a good inquiry even though the doctor knows.</p>
<p>I don’t have as snappy a story about her next example, Affair. I have several inconclusive thoughts about it.</p>
<ol style="list-style-type: decimal">
<li>It strikes me as less compelling that it is coherent</li>
<li>It’s striking that it gets much less attention than surgeon; I wonder if others share my suspicion (but maybe Surgeon is just first)</li>
<li>Feels like loose talk, like “I knew there was a fire here”, or “I knew we’d lose the game”</li>
<li>Or maybe it’s just an information possession sense of ‘knows’. We sometimes use that as well, and it’s very different to what the vast majority of epistemologists talk about. (Maybe not contextualists, maybe not Dretske.)</li>
<li>In any case, I’m not committed to ordinary usage being good around here. I’m aiming to find a theoretically interesting notion that fits the roles knowledge should fit.</li>
</ol>
</div>
<div id="need" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> The Need to Inquire<a href="inquiry.html#need" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So far I’ve mostly talked about inquiries that a person is actually conducting. But we should also think about the inquiries that they should conduct. Consider the following two abstractly described possibilities.</p>
<p>A person believes <em>p</em> for good reasons, and it is true, and there are no weird things happening that characterise typical gaps between rational true belief and knowledge. There is some action Φ they are considering that will have mildly good consequences if <em>p</em>, and absolutely catastrophic consequences if ￢<em>p</em>. And one of the alternatives to Φ is first checking whether <em>p</em>, which would be trivial, and then doing Φ iff <em>p</em>. We’ve seen lots of these cases before, but here’s the new twist. The person absolutely does not care about the catastrophic consequences. They will all fall on people the person could not care less about. So they are planning to simply do Φ, for the good consequences. Since <em>p</em> is true, nothing bad will happen. Still, it seems something has gone wrong. We want to say that they’ve been reckless, that they’ve taken an immoral risk. But it isn’t risky to do something that you know won’t have bad consequences. So they do not know that <em>p</em>, and for similar reasons to why Anisa doesn’t know that <em>p</em>. Yet the version of IRT that I’ve given so far doesn’t say that they don’t know that <em>p</em>.</p>
<p>The second case has the same initial structure as the first. The person believes <em>p</em> for good reasons, it’s true, and there is no funny business going on - no fake barns or the like blocking knowledge. They are thinking about doing Φ. They know that if <em>p</em> is true, Φ will have a small benefit. They also know that it would be completely trivial to verify whether <em>p</em> is true. They also in some sense know that if they do Φ, and <em>p</em> is false, it will be absolutely catastrophic. And they care about the catastrophe. But they’ve sort of forgotten this fact about Φ. It’s not that it has totally vanished from their mind. But they aren’t attending to it, and it doesn’t form any part of their deliberation when thinking about Φ. So they do Φ, nothing bad happens, and later when someone asks them whether they were worried about the possible catastrophe, they are shocked that they would do something so reckless. They are shocked, that is, that they forgot that it was important to confirm whether <em>p</em> was true before doing Φ. It feels, from the inside, like they got away with taking a terrible risk. But if they knew <em>p</em>, it should not seem like a risk, it should seem like rational action. (Just like they would think doing Φ after checking whether <em>p</em> was rational action.) So this too should be a case where we say knowledge fails for practical reasons. (I’m going to come back to a version of this case in section <a href="ratbel.html#atomism">8.1</a>, where it will be useful for distinguishing one of the few points where I disagree with the theory that Jeremy Fantl and Matthew McGrath <span class="citation">(<a href="references.html#ref-FantlMcGrath2002" role="doc-biblioref">Fantl and McGrath 2002</a>, <a href="references.html#ref-FantlMcGrath2009" role="doc-biblioref">2009</a>)</span> endorse.)</p>
<p>The natural thing to say here is that in each case, the person should conduct an inquiry. They should check whether <em>p</em> is true. And in that inquiry, they shouldn’t take <em>p</em> for granted. And they shouldn’t take it for granted for a very particular reason, because it might be false. The fact that they aren’t …</p>
<ul>
<li>If one should inquire into Q, and were one to inquire into Q, one shouldn’t take p for granted, one doesn’t know p</li>
<li>So there is a kind of moral encroachment into knowledge</li>
<li>Maybe move some chapter 8 stuff here</li>
<li>Note this is asymmetric; inquiries you don’t need to conduct can lose knowledge</li>
</ul>
</div>
<div id="realism" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Inquiry Realism<a href="inquiry.html#realism" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>There’s a fact of the matter about what people are inquiring about - and what they are doing with that inquiry.</li>
<li>This is independent of what their credences are</li>
<li>And there are facts about what they should inquire about; some of these are given by consequentialist considerations, some by (broadly) deontological</li>
<li>They may be inquiring into multiple things; this is ok, they lose a lot of information, but they retain probabilistic information</li>
<li>So this makes the current view sit uneasily in the current dualism/reductionism debate</li>
<li>I do think belief is reducible to credences plus subjects of inquiry</li>
<li>But I don’t think they are reducible to credences alone</li>
<li>Is this dualism or not? I don’t really care.</li>
</ul>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="33">
<li id="fn33"><p>These are contrasts, but they don’t exhaust the space. One might not have an attitude to a question. And one might not treat a question as settled while not inquiring into it, because one treats the question as unworthy of effort, or impossible to make progress on.<a href="inquiry.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>These quotes were compiled by Woodard <span class="citation">(<a href="references.html#ref-Woodard2021" role="doc-biblioref">2020</a>)</span>.<a href="inquiry.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>The picture I’m about to give is really similar to the one laid out by Andy Egan <span class="citation">(<a href="references.html#ref-Egan2008" role="doc-biblioref">2008</a>)</span>. We’re interested in different kinds of cases, but the idea that a cognitive system might work best by allowing one part to check on another using just the evidence the first part has endorsed is one I’m just taking from him. If I’d seen this connection when writing <em>Normative Externalism</em> I would have connected it to the discussion of Madisonian moral psychology in part I of that book.<a href="inquiry.html#fnref35" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="knowledge.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ties.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Kahis.pdf", "Kahis.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
