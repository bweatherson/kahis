So that shows that IRT satisfies Single Premise Closure. Showing it satisfies Multiple Premise Closure is also non-trivial. The problem arises with a different version of the red-blue game.

In this version, the red sentence is, once again, _Two plus two equals four_. And the blue sentence is a conjunction _A and B_, where both $A$ and $B$ express historical facts that the player has excellent, but not perfect, evidence for. Now the following four claims all seem true.

1. Unconditionally, the only rational play is Red-True.
2. Conditional on $A$, the only rational play is Red-True. Even given $A$, playing Blue-True requires betting that $B$ is true, and that's a pointless risk to run when playing Red-True only requires that two and two make four.
3. Conditional on $B$, the only rational play is Red-True. Even given $B$, playing Blue-True requires betting that $A$ is true, and that's a pointless risk to run when playing Red-True only requires that two and two make four.
4. Conditional on $A \wedge B$, Blue-True is rationally permissible, and arguably rationally mandatory, since it weakly dominates Red-True.

So conditionalising on either one of $A$ or $B$ doesn't change anything, but conditionalising on $A \wedge B$ does change how the player answers a question. So it looks like in this case the player might know $A$, know $B$, and for all I've said be fully aware that these two things entail $A \wedge B$, but not know $A \wedge B$. How should we respond to this?

One response is simply to accept it. Lots of theories deny that knowledge of the conjuncts suffices for knowledge of the conjunction. The usual motivation is that if knowledge is fallible, then accepting the conjunction might be more risky than accepting either conjunct. And if knowledge requires only accepting a small risk, then the conjuncts will be known but not the conjunction. (This is why @Hawthorne2005, in a very prominent defence of closure principles, declines to endorse Multiple Premise Closure.)

But I'm not happy to settle for this kind of response. As I'll argue in section \@ref(lockepuzzles), blatant violations of Multiple Premise Closure like this lead to really unintuitive consequences. And as I'll argue in chapter \@ref(preface), the main real world example that is used to back up the anti-closure intuitions, the preface paradox, doesn't show as much as its proponents suggest. So I'm going to look elsewhere for a solution.

I used to suggest this problem could be solved the same way puzzles about Single Premise Closure could be solved: with a technical and expansive notion of an interesting question. Assume that one is interested in the question _If p, Q?_, in the technical sense relevant to IRT, whenever one is interested in both _p_ and _Q?_. Then the player will be interested, in this technical sense, in the question _If A, what should I do in the game?_. And the unconditional answer to that is _Play Red-True_, while conditional on $B$ the answer is _Play Blue-True, and maybe Red-True is permissible_. So conditionalising on $B$ changes the answer to a question they have a (technical) interest in, so they don't know $B$. A parallel argument shows they don't know $A$. And so this isn't a failure of Multi-Premise Closure; the player doesn't actually know each of the conjuncts.

This is better than the previous response, but it still isn't great. It has two flaws. One is that it is very hard to motivate this technical notion of interest. Why should we care whether conditionalising on $B$ changes the answer to a question like that? Another is that it seems to be too harsh. It says that the player loses knowledge in both conjuncts. And that seems wrong. At least in some cases, there doesn't seem to be anything wrong with the following internal monologue.

> Playing Red-True is betting that two plus two is four. Since $A$ is true, playing Blue-True is betting that $B$ is true. I'd rather bet that two plus two is four than that $B$ is true, so I'm playing Red-True.

That little bit of reasoning takes $A$ as given. And it seems (at least in some specifications of what $A$ and $B$ are, and what the player's evidence for them is), to be a good enough piece of reasoning. And it has been a working assumption that only known things can be taken as given. So it looks like this is a continuation of the game where the player knows that $A$. So a solution to the problem that implies that the player automatically loses knowledge in both conjuncts in cases like this looks wrong.

So what should we say instead? Here's the option I prefer. If the player doesn't engage in any reasoning where they rely on either $A$ or $B$, then it is indeterminate which of them that they know. If they start reasoning using one or the other, this indeterminacy is resolved in favor of the one they use. That is, if they start reasoning using $A$, then they know $A$ and do not know $B$. But if they start reasoning using $B$, then the know $B$ and do not know $A$. But if they do neither, it is indeterminate which they know, though it is determinate that they know exactly one of them.

The advantages of this position are that it keeps Multiple Premise Closure, it keeps the idea that the player is entitled to reason with either of the conjuncts (though not with both at once), and it keeps the idea that the player loses knowledge in the conjunction since they are no longer entitled to rely on it. The big disadvantage is that it requires introducing this very unfamiliar notion, that knowledge claims could be indeterminate because of interest-relativity. 

I don't have a great sense of how to weigh these up. I'll just note that if one thinks this kind of indeterminacy is unacceptable, it's perfectly compatible with IRT to simply reject Multiple Premise Closure and say that in cases like this one the player knows $A$, knows $B$, and fails to know $A \wedge B$. I think it's better to live with indeterminacy than to reject closure in this way, but I'm more concerned to defend IRT than defend this intuition.

If we are allowed indeterminacy, then we can get a fairly strong form of multi-premise closure. The key point is that the interest-relative constraint on knowledge boils down to the idea that knowing that $p$ requires rationally taking $p$ for granted. That has a descriptive element, i.e., taking $p$ for granted; and a normative element, i.e., that that very taking is rational. The puzzle arises in just those games where all the following things are true.

1. Other things equal, the player can rationally take $A$ for granted.
2. Other things equal, the player can rationally take $B$ for granted.
3. The player cannot rationally take $A \wedge B$ for granted.

And note that if 3 is true, then the player cannot rationally both take $A$ for granted and take $B$ for granted. This doesn't contradict 1 and 2; there are plenty of cases where some actions that are individually permissible are not jointly permissible. And I'll return to that point a bit in what follows. But it does put some constraints on a possible counter-example to closure.

If we have a case where the player knows $A$, knows $B$, but their inference of $A \wedge B$ from those premises is not knowledge preserving, then they must be taking $A$ for granted, and they must be taking $B$ for granted. If those two things aren't true, then they don't both know $A$ and know $B$. But we just said that they cannot rationally take both these things for granted. So they don't know both, contradicting the assumption that they did. So it is impossible that there is a counterexample to Multi-Premise Closure.

That argument is unsatisfying in one important sense. It tells us that there could not be a counterexample, but it does not tell us what actually happens in games like the Red-Blue game that look like they will generate counterexamples. To say something more positive, it helps to think about analogies from ethics.

My model for preserving Multi-Premise Closure is a lot like the model offered by Thomas @Kroedel2012 as a solution to the preface paradox. He argues that we can solve the preface paradox if we take justification to be a kind of permissibility, not a kind of obligation. And just as we can have individual permissions that don't combine into a collective permission, we can have individually justified beliefs that are such that we can't justifiably believe each of them. This isn't exactly how I'd put it. For one thing, I'm talking about knowledge not justification. For another, it's not that knowledge is a species of permission, as much as it behaves like permission in certain contexts, and those are just the contexts where counterexampes to Multi-Premise Closure arise. But these are minor points of difference; I'm agreeing in large part with his model.

So let's think for a minute about a case where permissions do not agglomerate. Professor Paresseux is, like most academics, in a situation where professional morality requires he do his fair share, but is fairly open about what tasks he does that will constitute doing his fair share. Right now he has two requests for work, R1 and R2, and while he is not obliged to do both, he is obliged to do at least one. So he may turn down R1, and he may turn down R2, but he may not turn down both. So as not to keep the reader in suspense, let's say up front that he is going to turn down both. Our question will be, what exactly does Professor Paresseux do that's wrong?

To make this a little more concrete, and a little more complicated, I want to add two features to the case. First, accepting R1 would be better than accepting R2. He is uniquely well placed to do R1, and it would create more work for others if he turns it down. (As, indeed, he will.) But the norms governing Professor Paresseux are not maximising norms, and he does not violate them if he accepts R2 and rejects R1. Second, Professor Paresseux first turns down R1, let's say in the morning, and then later that day, let's say after a hearty lunch, turns down R2. Given that, there are three models we can have for the case, all of which have some plausibility.

The first model says that he was wrong to turn down R1. Here's a little argument for that, using language that seems natural. He should have accepted one of the requests. And since he was well placed to perform R1, it's also true that if he did one of them, it should have been R1. So he should have accepted R1, and turning it down was the mistake. Oddly, it turns out to have been made true that he did the wrong thing in turning down R1 by his latter decision to turn down R2, but that's just an odd feature of the case.

The second model says that odd feature is intolerably odd. It says he was wrong to turn down R2. Here's a little argument for that. At lunchtime, he hadn't done anything wrong. True, he had turned down R1, but he had moral permission to do that. It was only after lunch that he made it the case that he violated a norm. So the violation must have been after lunch. And so the violation was in turning down R2.

A third model says that both of these arguments are inconclusive. What's really true is simply that Professor Paresseux should not have turned down both requests. Which one individually was wrong? That, says the third model, is indeterminate. One of them must be, since it