## Beliefs and Interests {#beliefsinterests}

In my earliest work on interest-relativity, the 2005 paper "Can We Do Without Pragmatic Encroachment", I argued for a belief-first approach to interest-relativity. In particular, I conceived of that paper as the start of a project where I would argue (a) that belief itself is interest-relative, and (b) that all the interest-relativity in epistemology could trace back to the interest-relativity of belief. The core idea was that the metaphysics of mind should be interest-relative, but the normative theory of mind need not be. Of course, if a state is by its nature interest-relative, then whether one ought be in that state could quite easily turn out to be interest-relative as well. But the thought was that interest-invariant norms, combined with interest-relative metaphysics, could explain all the phenomena.

This approach did not work out. The model of that paper assumed a very high degree of rationality on the part of the agents being modelled, and it turns out to be very hard to extend the model to less rational agents. (Kieran Setiya was the first to point out this problem to me.) Jacob Ross and Mark Schroeder -@RossSchroeder2014 pointed out that the way the model handled propositions that are irrelevant to one's practical interests wasn't working. In "Games, Beliefs and Credences" I suggested a 'fix', but I didn't really appreciate how much the fix undermined the motivations for the original view. 

In this book I'm taking a different approach. For one thing, I am defending a much more expansive picture of how interests affect epistemology. In chapter \@ref(evidence) I'm going to argue that evidence itself is interest-relative, and hence so is everything that depends on evidence. And in chapter \@ref(knowledge), I'm going to argue that a version of what Jason @Stanley2005 calls 'ignorant high stakes' cases shows that some of the interest-relativity of knowledge is not tracable to the interest-relativity of either belief or of rational belief.

And I'm going to offer a much more complicated story about the constitutive connection between interests and beliefs than I offered earlier. While I still think there is scuh a connection, I'm much more sympathetic to the suggestion by Jennifer Nagel [-@Nagel2008; -@Nagel2010] that often there is a merely causal connection. Some people's beliefs change when the practical situation changes because the situation causes them to see that it would be a mistake to hold on to their prior beliefs. This isn't interest-relativity in the sense we're most interested in. Where I disagree with Nagel is that I think that for at least some people, the change in belief upon change in interests is more direct, and plausibly the change in interests is partially constitutive of the change in belief. But the situation is much messier than I had realised in earlier work, and Nagel's work revealed how I'd been over-simplifying things.

The positive theory I'm going to develop owes a lot to proposals by Dorit Ganson [-@Ganson2008; -@Ganson2019]. Like her, I'm going to develop a theory where we first say what it is to have a belief in normal cases, then include an exception clause for what happens in special cases, such as high-stakes or long-odds. The details will differ in some respects, but the underlying architecture will be the same.

But perhaps the biggest difference is one motivated by work by Jonathan Weisberg [-@Weisberg2013; -@Weisberg2020]. In the 2005 paper, I argued that what we should say someone believed is something we reconstruct from their patterns of preferences. At a high level of generality, my theory was that you could look at the outputs of someone's deliberation, and construct from that what they believed. This was a quite radical version of radical interpretation. I now think I was looking in the wrong spot. What someone believes is a matter of what inputs to deliberation they are willing to accept, not the results of those deliberations. If we assume perfect rationality, this distinction may not matter. The outputs of deliberations (taken collectively) might well imply what inputs had been accepted. But that's too strong an assumption; and for anything other than perfectly rational thinkers, we can't infer what starting points they are willing to accept from what points they end up at.

What's essential to belief, I now think, is that to believe something is to be willing to use it as a starting point in deliberation. That slogan needs a lot of qualification to be a theory, but as a slogan it isn't a bad starting point.
