## Blocking Belief {#block}

Imagine a person, call him Erwan, who is made the offer Blaise is made, but declines it. He declines on the very sensible grounds that the Battle of Agincourt might not have been in 1415, and he does not want to run the risk of sending everyone to the Bad Place. If we stop our theory of belief with **Given**, then we have to say that Erwin has some kind of weird pragmatic incoherence. He believes that $p$, and wants what is best for everyone, but won't do the thing that will, given his beliefs, produce what is best for everyone. Declining the bet is not practically incoherent in this way. So Erwin does not believe that the Battle of Agincourt was in 1415. At least, he doesn't believe that at the time he is declining the bet.

So a theory of belief with any hope of being complete needs some supplementation. The idea I'll use is one that seems prima facie like it might apply without restriction. A little reflection, however, shows that it will ultimately need to be restricted, and the most natural restrictions are pragmatic.

Imagine that we don't ask Erwin whether he is prepared to bet the welfare of all of humanity on historical claims, but instead ask him a simple factual question (H).

(H) How many (full) centuries has it been since the Battle of Agincourt?

Erwin will think to himself, "Well, the Battle of Agincourt was in 1415, and that's a bit over 600 years ago, so that's six centuries. The answer is six." Now compare what happens if we ask him this slightly more convoluted question.

(I) If the Battle of Agincourt was in 1415, how many (full) centuries has it been since the Battle of Agincourt?

Erwin will give the same answer, i.e., six. And he will give it for basically the same reasons. Indeed, apart from the date of the Battle being one of his reasons in answering (H), and not needed to answer (I), he has the same reasons for answering the two questions with six. I mean that both in the sense that what justifies giving the answer six is the same for the two questions, and in the sense that what causes him to answer six is the same for the two questions. (With the exception that the date of the Battle is a reason in answering (H), but not in answering (I).)

Say that a person answers the questions _Q?_ and _If p, Q?_ in the same way if they offer the same answer to the two questions, and their reasons (in both senses) for these answers are the same except only that $p$ is one of the reasons for their answer to _Q?_. Then here is a plausible principle about belief - albeit one that isn't going to be quite right.

Unrestricted Conditional Questions
:    If _S_ believes that $p$, then for any question _Q?_, S is disposed to answer the questions _Q?_ and _If p, Q?_ the same way.

Note that in saying these questions are answered the same way, I really don't just mean that they get the same answers. I will offer the same answer to the questions _What is one plus one?_ and _What is the largest $n$ such that $x^n + y^n = z^n$ has positive integer solutions?_, but I don't answer these questions the same way. My reasons for the first answer are quite closely related to the fact that one plus one does equal two. My reasons for the second answer are almost wholly testimonial. So in the sense relevant to **Unconditional Conditional Questions**, I do not answer each question the same way. 

I'm understanding what a conditional question is in a particular way. I think this is how conditional questions usually work in English, so the shorthand _If p, Q?_  that I'm using is not misleading. But I don't intend to defend a particular claim about the way natural language conditionals work. That would be another whole book. (Or more.) So I intend to use this shorthand _If p, Q?_ somewhat stipulatively. 

_If p, Q?_ is the question _Q?_ asked under the assumption that _p_ can be taken as given. So the question _If p, how probable is q?_ is asking for the conditional probability of $q$ given $p$. The question _If p, which option is most useful?_ is asking for a comparison of the conditional utilities of the various options. And the question _If p, must it be that q?_ gets an affirmative answer if all the (salient) possibilities where $p$ is true are ones where $q$ is true. (So it becomes very close to asking if the material implication $p \supset q$ must be true.) Now notoriously it is difficult to connect these conditional questions with questions about the truth of any conditional.^[See Lewis [-@Lewis1976b; -@Lewis1986h] on the issues about conditional 'how probable' questions; Lewis [-@Lewis1988; -@Lewis1996] on the issues about conditional 'how useful' questions; and @Gillies2010 on issues about modals in the consequent of conditional questions.] But I'm setting all those issues aside here. Everything that I say about conditional questions I could say, more verbosely, by making it explicit that they are to be understood as questions about conditional probability, conditional utility, conditional modality, and so on.

Now thinking about a few simple cases might make it seem that **Unrestricted Conditional Questions** is true. After all, there is something very odd about a counterexample to it. It would have to be a case where _S_ believes that $p$, and there is a way they are disposed to get answer _If p, Q?_, i.e., to get from $p$ to an answer to _Q?_, but they are not disposed to use that to answer _Q?_. That seems at best rather odd.

Let me mention one potential counterexample that I don't think undermines **Unrestricted Conditional Questions**. There could be a case where I believe $p$, and $p$ is relevant to _Q?_, but I don't realise its relevance. On the other hand, when I am explicitly asked _If p, Q?_, being reminded of $p$ makes me see the connection, so I follow the natural path from $p$ to an answer to _Q?_. These kind of one-off performance errors are, sadly, easy to make. But as long as they are one-off, they don't threaten the principle connecting dispositions.

But a bigger problem comes from the two cases that I started the book with. If the Battle of Agincourt was in 1415, then Anisa maximises expected utility by playing blue-true, and Blaise maximises expected utility by taking the bet. So  answer to the conditional questions _If the Battle of Agincourt was in 1415, what options of Anisa's maximse expected utility?_ and _If the Battle of Agincourt was in 1415, what option of Blaise's maximses expected utility?_ have different answers to the corresponding unconditional questions. Or at least so say I, and hope you do too. So if **Unrestricted Conditional Questions** is true, then none of us have ever believed that the Battle of Agincourt was in 1415. That can't be right, so there must be some restriction on the principle.

Happily, a restriction isn't too hard to find. The principle just needs to be restricted to questions that the subject is currently taking an interest in. When we're thinking about questions like (H) and (I), then we do have beliefs about when the Battle of Agincourt was. Were we to be placed in Anisa or Blaise's situation, or arguably when we even think about their situation, we lose this belief. So I suggest the following principle is true, and explains a lot of the cases that have been discussed so far.

Relevant Conditional Questions
:    If _S_ believes that $p$, then for any question _Q?_ that _S_ is currently taking an interest in, _S_ is disposed to answer the questions _Q?_ and _If p, Q?_ the same way.

As I argued in \@ref(whatinterests), whether one is interested in a question isn't just a matter of one's practical situation. One can be interested in a question because one is thinking about what to do should it arise, or because one is just naturally inquistive. Many of the questions we're interested in are practical questions, but not all of them are.

So I've argued that **Given** and **Relevant Conditional Questions** are necessary conditions on belief. And very roughly, I think they are jointly sufficient for belief. I say 'roughly' because I don't mean to take a stance on, say, whether animals have beliefs, or whether one can have singular thoughts about things one is not acquainted with. A more accurate claim is that if it is plausible that _S_ is the kind of thing that can have beliefs, and _p_ is the kind of thing it could in principle have beliefs about, and both **Given** and **Relevant Conditional Questions** are satisfied, then _S_ believes that _p_.

Obviously neither **Given** and **Relevant Conditional Questions** would be particularly helpful principles to use in providing a reductive physicalist account of mental content. They say something about necessary conditions for belief, but the statement of those conditions makes a lot of assumptions about other content-bearing states of the agent. So even if these conditions are individually necessary and jointly sufficient for belief, they wouldn't be any kind of analysis or reduction of belief.^[Compare: One can consistently deny that any analysis or reduction of _knowledge_ is possible and say that the condition _p is part of S's evidence_ is both necessary and sufficient for _S_ to know that _p_.] But they could be part of a theory of belief, and the theory they are part of is helpful for seeing how beliefs and interests fit together.
