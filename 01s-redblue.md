## Red or Blue? {#redblue}

The key argument that knowledge is interest-relative starts with a puzzle about a game. Here are the rules of the game, which I'll call the Red-Blue game.

1.  Two sentences will be written on the board, one in red, one in blue.
2.  The player will make two choices.
3.  First, they will pick a colour, red or blue.
4.  Second, they say whether the sentence in that colour is true or
    false.
5.  If they are right, they win. If not, they lose.
6.  If they win, they get \$50, and if they lose, they get nothing.

Our player is Anisa. She has been reading some medieval history, and last night was reading about the Battle of Agincourt. She was amused to see that it too place on her birthday, October 25, and in 1415, precisely 595 years before her own birthday. The book says all these things about the Battle of Agincourt because they are actually true, and when she read the book, Anisa believed them. She believed them because she had lots of independent evidence that the book was reliable (it came from a respected author and publisher, it didn't contradict her well-grounded background beliefs), and she was sensitive to that evidence of its reliability. And, indeed, the book was generally reliable, as well as accurate on this point.

Anisa comes to know that she is playing the Red-Blue game, and that these are its rules. She does not come to know any other relevant fact about the game. When the game starts, the following two sentences are written on the board, the first in red, the second in blue.

*  Two plus two equals four.
*  The Battle of Agincourt took place in 1415.

Anisa looks at this, thinks to herself, "Oh, my book said that the Battle of Agincourt was in 1415, so (given the rules of the game) playing Blue-True will be as good as any other play, so I'm playing Blue-True. Playing Red-True would get the same amount, since obviously two plus two is four, but I'm going to play Blue-True instead". And that's what she does, and she wins the $50.

Intuitively, Anisa's move here is irrational. It doesn't cost her anything - she gets the $50. And it's not that irrational as these things go - she costs herself $50 in the somewhat distant worlds where her reliable book gets this fact wrong. But it was still irrational. She took a needless risk, when there was a simple safe option on the table.

I'm going to argue, at some length, that the best explanation of why it is irrational for Anisa to play Blue-True is that knowledge is interest-relative. Given her interests in learning about late medieval history, when she was at home reading the book, Anisa knew that the Battle of Agincourt did take place in 1415. Given her interests in playing this game well, Anisa does not know this. When she is moved into the game situation, she loses some knowledge she previously had.

Interest-relativity is often taken to be a wild and radical development in the theory of knowledge. And it is certainly a reform. It's not a new reform proposal; both the proposal, and many of the details, are set out in works by Jeremy Fantl and Matthew McGrath [-@FantlMcGrath2002; -@FantlMcGrath2009], John @Hawthorne2004, and Jason @Stanley2005. But relative to the epistemological status quo circa 1990, it is different. But then again, factors that were widely held to affect knowledge according to the status quo of either today or of 1990 would have seemed wild and radical relative to the epistemological status quo circa 1960. The factors that make a belief safe, or sensitive, or reliable, or undefeated, were well outside the realms of factors that late 20th century epistemologists thought relevent to knoweldge. There are many things that are irrelevant to how probable a belief is that are relevant to whether it is knowledge, as the epistemological literature of the late 20th Century makes clear. The proposal here is that interests are one more addition to this motley bunch.

The standard arguments for and against interest-relativity to date have not focussed on examples like Anisa's, but on examples like Blaise that I'll present shortly. There are exceptions. The structure of Anisa's example is similar, in the features that matter to me, to the examples of low-cost checking that Bradley @ArmourGarb2011 discusses. (Though he draws contextualist conclusions from these examples, not interest-relative ones.) And it is similar to some of the cases of three-way choice that Charity Anderson and John Hawthorne deploy in arguing against interest-relativity [-@AndersonHawthorne2019a; -@AndersonHawthorne2019b]. But mostly people have focussed on cases like the following.

Last night, Blaise was reading the same book that Anisa was reading. And he too was struck by the fact that the Battle of Agincourt took place on October 25, 1415. Today he is visited by a representative of the supernatural world, and offered the following bet. (Blaise knows these are the terms of the bet, and doesn't know anything else relevant.) If he declines the bet, life will go on as normal. If he accepts, one of two things will happen.

* If it is true that the Battle of Agincourt took place in 1415, an infant somewhere will receive one second's worth of pure joy, of the kind infants often get playing peek-a-boo.
* If it is false that the Battle of Agincourt took place in 1415, all of humanity will be cast into The Bad Place for all of eternity.

Blaise takes the bet. The Battle of Agincourt was in 1415, and he can't bear the thought of a lovable baby missing that second of pure joy.
 
Again, there is an intuition that Blaise did something horribly wrong here. And this intuition is best explained, I will argue, by letting knowledge be interest-relative. But the argument that the interest-relativity of knowledge is the best explanation of what's going on is, in my view, somewhat weaker in Blaise's case than in Anisa's. It's not that I think the interest-relative explanation of the case is wrong; in fact I think it's basically correct. It's rather that there are somewhat more plausible interest-invariant explanations of Blaise's case than of Anisa's. So I'll focus on Anisa, not Blaise.

This choice of focus occasionally means that this book is less connected to the existing literature than I would like. I occasionally infer what a philosopher would say about cases like Anisa from what they have said about cases like Blaise. And I suspect in some cases I'll get those inferences wrong. But I want to set out the best argument for the interest-relativity of knowledge that I know, and that means going via the example of Anisa.

Though I am starting with an example, and with an intuition about it, I am not starting with an intuition about what is known in the example. I don't have any clear intuitions about what Anisa knows or doesn't know while playing the Red-Blue game. The intuition that matters here is that her choice of Blue-True is irrational. It's going to be a matter of inference, not intuition, that Anisa lacks knowledge.

And that inference will largely be by process of elimination. In section \@ref(fourfamilies) I will set out four possible things we can say about Anisa, and argue that one of them must be true. (The argument won't appeal to any principles more controversial than the Law of Excluded Middle.) But all four of them, including the interest-relative view I favour, have fairly counterintuitive consequences. So something counterintuitive is true around here. And this puts a limit on how we can argue. At least one instance of the argument _this is counterintuitive, so it is false_ must fail. And that casts doubt over all such arguments. This is a point that critics of interest-relativity haven't sufficiently acknowledged, but it also puts constraints on how one can defend interest-relativity.

When Anisa starts playing the Red-Blue game, her practical situation changes. So you might think I've gone wrong in stressing Anisa's interests, not her practical situation. I've put the focus on interests for two reasons. One is that if Anisa is totally indifferent to money, then there is no rational requirement to play Red-True. We need to posit something about Anisa's interests to even get the data point that the interest-relative theory explains. The second reason, which I'll talk about more in section \@ref(whatinterests), is that sometimes we can lose knowledge due to a change not in our practical situation, but our theoretical interests.

In the existing literature, views like mine are sometimes called versions of **subject-sensitive invariantism**, since they make knowledge relevant to the stakes and salient alternatives available to the subject. But this is a bad name; of course whether a knowledge ascription is true is sensitive to who the subject of the ascription is. I know what I had for breakfast and you (probably) don't. What is distinctive is which features of the subject's situation that the interest-relative theory says are relevant, and calling it the interest-relative theory of knowledge  makes it clear that it is the subject's interests. In the past, I've called it **interest-relative invariantism**. But, for reasons I'll say more about in section \@ref(neutrality), I'm not committed to _invariantism_ in this book. So it's just the interest-relative theory, or IRT.
